#!/usr/bin/env python3
"""
ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ ë°©ë²•ë“¤
GPU ì—†ì´ë„ ì•ˆì „í•˜ê²Œ ë™ì‘í•˜ëŠ” ê°œì„  ë°©ë²•ë“¤
"""

import numpy as np
import librosa
import pandas as pd
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import accuracy_score, classification_report
from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
import joblib
from typing import Dict, List, Tuple, Optional
import warnings
import time
import threading
from concurrent.futures import ThreadPoolExecutor
warnings.filterwarnings('ignore')

class NoRiskAccuracyImprovements:
    """ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ ë°©ë²•ë“¤"""
    
    def __init__(self):
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.models = {}
        self.feature_importance = {}
        self.performance_cache = {}
        
        print("ğŸš€ ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ ë°©ë²•ë“¤ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ===== 1. ë°ì´í„° ì¦ê°• (Data Augmentation) =====
    
    def augment_audio_data(self, audio_data: np.ndarray, sr: int, 
                          augmentation_factor: int = 2) -> List[np.ndarray]:
        """ì•ˆì „í•œ ì˜¤ë””ì˜¤ ë°ì´í„° ì¦ê°•"""
        augmented_data = [audio_data]  # ì›ë³¸ í¬í•¨
        
        try:
            for i in range(augmentation_factor):
                # 1. ë…¸ì´ì¦ˆ ì¶”ê°€ (ì•ˆì „í•œ ë²”ìœ„)
                noise_factor = np.random.uniform(0.001, 0.005)  # ë§¤ìš° ì‘ì€ ë…¸ì´ì¦ˆ
                noise = np.random.normal(0, noise_factor, len(audio_data))
                noisy_audio = audio_data + noise
                augmented_data.append(noisy_audio)
                
                # 2. ì‹œê°„ ë³€í˜• (ì•ˆì „í•œ ë²”ìœ„)
                speed_factor = np.random.uniform(0.95, 1.05)  # 5% ë²”ìœ„ ë‚´
                if speed_factor != 1.0:
                    try:
                        time_stretched = librosa.effects.time_stretch(audio_data, rate=speed_factor)
                        # ê¸¸ì´ ë§ì¶”ê¸°
                        if len(time_stretched) > len(audio_data):
                            time_stretched = time_stretched[:len(audio_data)]
                        else:
                            time_stretched = np.pad(time_stretched, (0, len(audio_data) - len(time_stretched)))
                        augmented_data.append(time_stretched)
                    except:
                        pass
                
                # 3. ë³¼ë¥¨ ì¡°ì ˆ (ì•ˆì „í•œ ë²”ìœ„)
                volume_factor = np.random.uniform(0.9, 1.1)  # 10% ë²”ìœ„ ë‚´
                volume_adjusted = audio_data * volume_factor
                augmented_data.append(volume_adjusted)
                
                # 4. ì‹œê°„ ì´ë™ (ì•ˆì „í•œ ë²”ìœ„)
                shift_samples = np.random.randint(0, len(audio_data) // 10)  # 10% ë²”ìœ„ ë‚´
                shifted_audio = np.roll(audio_data, shift_samples)
                augmented_data.append(shifted_audio)
                
        except Exception as e:
            print(f"âš ï¸ ë°ì´í„° ì¦ê°• ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
        
        return augmented_data
    
    # ===== 2. ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ (Advanced Feature Extraction) =====
    
    def extract_advanced_features(self, audio_data: np.ndarray, sr: int) -> Dict[str, float]:
        """ê³ ê¸‰ ì˜¤ë””ì˜¤ íŠ¹ì§• ì¶”ì¶œ (ì•ˆì „í•œ ë²„ì „)"""
        features = {}
        
        try:
            # 1. MFCC (ì•ˆì „í•œ ë²”ìœ„)
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            features['mfcc_mean'] = np.mean(mfccs, axis=1).tolist()
            features['mfcc_std'] = np.std(mfccs, axis=1).tolist()
            
            # 2. Chroma (ìŒê³„ íŠ¹ì§•)
            chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)
            features['chroma_mean'] = np.mean(chroma, axis=1).tolist()
            features['chroma_std'] = np.std(chroma, axis=1).tolist()
            
            # 3. Spectral Contrast
            contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sr)
            features['contrast_mean'] = np.mean(contrast, axis=1).tolist()
            features['contrast_std'] = np.std(contrast, axis=1).tolist()
            
            # 4. Zero Crossing Rate
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features['zcr_mean'] = np.mean(zcr)
            features['zcr_std'] = np.std(zcr)
            
            # 5. Spectral Rolloff
            rolloff = librosa.feature.spectral_rolloff(y=audio_data, sr=sr)
            features['rolloff_mean'] = np.mean(rolloff)
            features['rolloff_std'] = np.std(rolloff)
            
            # 6. Spectral Bandwidth
            bandwidth = librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)
            features['bandwidth_mean'] = np.mean(bandwidth)
            features['bandwidth_std'] = np.std(bandwidth)
            
            # 7. Spectral Centroid
            centroid = librosa.feature.spectral_centroid(y=audio_data, sr=sr)
            features['centroid_mean'] = np.mean(centroid)
            features['centroid_std'] = np.std(centroid)
            
            # 8. RMS Energy
            rms = librosa.feature.rms(y=audio_data)
            features['rms_mean'] = np.mean(rms)
            features['rms_std'] = np.std(rms)
            
            # 9. Spectral Flatness
            flatness = librosa.feature.spectral_flatness(y=audio_data)
            features['flatness_mean'] = np.mean(flatness)
            features['flatness_std'] = np.std(flatness)
            
            # 10. Tempo (ì•ˆì „í•œ ë²”ìœ„)
            try:
                tempo, _ = librosa.beat.beat_track(y=audio_data, sr=sr)
                features['tempo'] = tempo if tempo is not None and 0 < tempo < 300 else 0.0
            except:
                features['tempo'] = 0.0
            
        except Exception as e:
            print(f"âš ï¸ ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ (ê¸°ë³¸ê°’ ì‚¬ìš©): {e}")
            # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
            features = {f'feature_{i}': 0.0 for i in range(50)}
        
        return features
    
    # ===== 3. íŠ¹ì§• ì„ íƒ (Feature Selection) =====
    
    def select_best_features(self, X: np.ndarray, y: np.ndarray, 
                           method: str = 'mutual_info', k: int = 20) -> np.ndarray:
        """ì•ˆì „í•œ íŠ¹ì§• ì„ íƒ"""
        try:
            if method == 'mutual_info':
                selector = SelectKBest(score_func=mutual_info_classif, k=min(k, X.shape[1]))
            elif method == 'f_score':
                selector = SelectKBest(score_func=f_classif, k=min(k, X.shape[1]))
            else:
                from sklearn.feature_selection import VarianceThreshold
                selector = VarianceThreshold(threshold=0.01)
            
            X_selected = selector.fit_transform(X, y)
            self.feature_selector = selector
            
            # íŠ¹ì§• ì¤‘ìš”ë„ ì €ì¥
            if hasattr(selector, 'scores_'):
                self.feature_importance = {
                    'scores': selector.scores_,
                    'selected_features': selector.get_support(indices=True)
                }
            
            return X_selected
            
        except Exception as e:
            print(f"âš ï¸ íŠ¹ì§• ì„ íƒ ì¤‘ ì˜¤ë¥˜ (ì›ë³¸ ì‚¬ìš©): {e}")
            return X
    
    # ===== 4. ì•¡í‹°ë¸Œ í•™ìŠµ (Active Learning) =====
    
    def active_learning_query(self, X: np.ndarray, model, 
                            query_strategy: str = 'uncertainty', n_queries: int = 10) -> np.ndarray:
        """ì•¡í‹°ë¸Œ í•™ìŠµì„ ìœ„í•œ ì¿¼ë¦¬ ìƒ˜í”Œ ì„ íƒ"""
        try:
            if query_strategy == 'uncertainty':
                # ë¶ˆí™•ì‹¤ì„± ê¸°ë°˜ ì„ íƒ
                pred_proba = model.predict_proba(X)
                uncertainty = 1 - np.max(pred_proba, axis=1)
                query_indices = np.argsort(uncertainty)[-n_queries:]
                
            elif query_strategy == 'diversity':
                # ë‹¤ì–‘ì„± ê¸°ë°˜ ì„ íƒ (í´ëŸ¬ìŠ¤í„°ë§)
                n_clusters = min(10, len(X) // 2)
                if n_clusters > 1:
                    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
                    cluster_labels = kmeans.fit_predict(X)
                    
                    # ê° í´ëŸ¬ìŠ¤í„°ì—ì„œ í•˜ë‚˜ì”© ì„ íƒ
                    query_indices = []
                    for cluster_id in range(n_clusters):
                        cluster_mask = cluster_labels == cluster_id
                        if np.any(cluster_mask):
                            cluster_indices = np.where(cluster_mask)[0]
                            query_indices.append(np.random.choice(cluster_indices))
                else:
                    query_indices = np.random.choice(len(X), size=min(n_queries, len(X)), replace=False)
                    
            else:  # random
                # ëœë¤ ì„ íƒ
                query_indices = np.random.choice(len(X), size=min(n_queries, len(X)), replace=False)
            
            return query_indices
            
        except Exception as e:
            print(f"âš ï¸ ì•¡í‹°ë¸Œ í•™ìŠµ ì¿¼ë¦¬ ì¤‘ ì˜¤ë¥˜ (ëœë¤ ì„ íƒ): {e}")
            return np.random.choice(len(X), size=min(n_queries, len(X)), replace=False)
    
    def active_learning_pipeline(self, X: np.ndarray, y: np.ndarray, 
                               initial_size: int = 100, query_size: int = 10, 
                               max_iterations: int = 10) -> Dict:
        """ì•¡í‹°ë¸Œ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
        try:
            # ì´ˆê¸° ë°ì´í„°ë¡œ ëª¨ë¸ í›ˆë ¨
            initial_indices = np.random.choice(len(X), size=min(initial_size, len(X)), replace=False)
            X_initial = X[initial_indices]
            y_initial = y[initial_indices]
            
            # ì´ˆê¸° ëª¨ë¸ í›ˆë ¨
            model = GradientBoostingClassifier(n_estimators=50, random_state=42)
            model.fit(X_initial, y_initial)
            
            # ì•¡í‹°ë¸Œ í•™ìŠµ ë°˜ë³µ
            labeled_indices = set(initial_indices)
            performance_history = []
            
            for iteration in range(max_iterations):
                # ì¿¼ë¦¬ ìƒ˜í”Œ ì„ íƒ
                unlabeled_mask = ~np.isin(np.arange(len(X)), list(labeled_indices))
                X_unlabeled = X[unlabeled_mask]
                
                if len(X_unlabeled) == 0:
                    break
                
                # ì¿¼ë¦¬ ìƒ˜í”Œ ì„ íƒ
                query_indices = self.active_learning_query(X_unlabeled, model, n_queries=query_size)
                actual_query_indices = np.where(unlabeled_mask)[0][query_indices]
                
                # ìƒˆë¡œìš´ ìƒ˜í”Œ ì¶”ê°€
                labeled_indices.update(actual_query_indices)
                X_labeled = X[list(labeled_indices)]
                y_labeled = y[list(labeled_indices)]
                
                # ëª¨ë¸ ì¬í›ˆë ¨
                model.fit(X_labeled, y_labeled)
                
                # ì„±ëŠ¥ í‰ê°€
                if len(labeled_indices) < len(X):
                    test_indices = np.random.choice(
                        [i for i in range(len(X)) if i not in labeled_indices],
                        size=min(50, len(X) - len(labeled_indices)),
                        replace=False
                    )
                    X_test = X[test_indices]
                    y_test = y[test_indices]
                    
                    y_pred = model.predict(X_test)
                    accuracy = accuracy_score(y_test, y_pred)
                    performance_history.append(accuracy)
                    
                    print(f"ì•¡í‹°ë¸Œ í•™ìŠµ ë°˜ë³µ {iteration + 1}: ì •í™•ë„ {accuracy:.3f}")
            
            return {
                'model': model,
                'performance_history': performance_history,
                'final_accuracy': performance_history[-1] if performance_history else 0.0,
                'total_labeled_samples': len(labeled_indices)
            }
            
        except Exception as e:
            print(f"âš ï¸ ì•¡í‹°ë¸Œ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'model': None, 'performance_history': [], 'final_accuracy': 0.0, 'total_labeled_samples': 0}
    
    # ===== 5. ì²˜ë¦¬ ì‹œê°„ ìµœì í™” =====
    
    def optimize_processing_time(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ì²˜ë¦¬ ì‹œê°„ ìµœì í™”"""
        try:
            # 1. íŠ¹ì§• ìˆ˜ ì¤„ì´ê¸°
            X_reduced = self.select_best_features(X, y, k=20)
            
            # 2. PCAë¡œ ì°¨ì› ì¶•ì†Œ
            pca = PCA(n_components=min(10, X_reduced.shape[1]))
            X_pca = pca.fit_transform(X_reduced)
            
            # 3. ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš©
            fast_model = RandomForestClassifier(
                n_estimators=50,  # íŠ¸ë¦¬ ìˆ˜ ì¤„ì´ê¸°
                max_depth=10,     # ê¹Šì´ ì œí•œ
                random_state=42
            )
            
            # 4. ì„±ëŠ¥ ì¸¡ì •
            start_time = time.time()
            fast_model.fit(X_pca, y)
            training_time = time.time() - start_time
            
            start_time = time.time()
            y_pred = fast_model.predict(X_pca)
            prediction_time = time.time() - start_time
            
            accuracy = accuracy_score(y, y_pred)
            
            return {
                'model': fast_model,
                'pca': pca,
                'accuracy': accuracy,
                'training_time': training_time,
                'prediction_time': prediction_time,
                'feature_count': X_pca.shape[1]
            }
            
        except Exception as e:
            print(f"âš ï¸ ì²˜ë¦¬ ì‹œê°„ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return {'model': None, 'accuracy': 0.0, 'training_time': 0.0, 'prediction_time': 0.0}
    
    # ===== 6. GPU ì—†ì´ ì•ˆì „í•œ ë”¥ëŸ¬ë‹ ì¤€ë¹„ =====
    
    def prepare_gpu_ready_code(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """GPU ì—†ì´ë„ ë™ì‘í•˜ëŠ” ë”¥ëŸ¬ë‹ ì¤€ë¹„ ì½”ë“œ"""
        try:
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            gpu_available = self._check_gpu_availability()
            
            if gpu_available:
                print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥ - ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‚¬ìš©")
                return self._create_deep_learning_model(X, y)
            else:
                print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€ - ì „í†µì  ML ëª¨ë¸ ì‚¬ìš©")
                return self._create_traditional_model(X, y)
                
        except Exception as e:
            print(f"âš ï¸ GPU ì¤€ë¹„ ì½”ë“œ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_traditional_model(X, y)
    
    def _check_gpu_availability(self) -> bool:
        """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def _create_deep_learning_model(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„± (GPU ì‚¬ìš©)"""
        try:
            import torch
            import torch.nn as nn
            
            # ê°„ë‹¨í•œ ì‹ ê²½ë§
            class SimpleNN(nn.Module):
                def __init__(self, input_size, hidden_size=64, output_size=2):
                    super().__init__()
                    self.fc1 = nn.Linear(input_size, hidden_size)
                    self.fc2 = nn.Linear(hidden_size, hidden_size)
                    self.fc3 = nn.Linear(hidden_size, output_size)
                    self.relu = nn.ReLU()
                    self.dropout = nn.Dropout(0.2)
                
                def forward(self, x):
                    x = self.relu(self.fc1(x))
                    x = self.dropout(x)
                    x = self.relu(self.fc2(x))
                    x = self.dropout(x)
                    x = self.fc3(x)
                    return x
            
            model = SimpleNN(X.shape[1])
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            model = model.to(device)
            
            return {
                'model': model,
                'device': device,
                'model_type': 'deep_learning',
                'gpu_available': True
            }
            
        except Exception as e:
            print(f"âš ï¸ ë”¥ëŸ¬ë‹ ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return self._create_traditional_model(X, y)
    
    def _create_traditional_model(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ì „í†µì  ML ëª¨ë¸ ìƒì„± (CPU ì‚¬ìš©)"""
        try:
            model = GradientBoostingClassifier(
                n_estimators=100,
                learning_rate=0.1,
                random_state=42
            )
            
            model.fit(X, y)
            
            return {
                'model': model,
                'device': 'cpu',
                'model_type': 'traditional',
                'gpu_available': False
            }
            
        except Exception as e:
            print(f"âš ï¸ ì „í†µì  ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}")
            return {'model': None, 'device': 'cpu', 'model_type': 'error', 'gpu_available': False}
    
    # ===== 7. í†µí•© ë…¸ë¦¬ìŠ¤í¬ íŒŒì´í”„ë¼ì¸ =====
    
    def no_risk_improvement_pipeline(self, audio_files: List[str], 
                                   labels: List[int]) -> Dict:
        """í†µí•© ë…¸ë¦¬ìŠ¤í¬ ê°œì„  íŒŒì´í”„ë¼ì¸"""
        
        print("ğŸš€ ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        
        try:
            # 1. ë°ì´í„° ì¦ê°• (ì•ˆì „í•œ ë²”ìœ„)
            print("1ï¸âƒ£ ì•ˆì „í•œ ë°ì´í„° ì¦ê°• ì¤‘...")
            augmented_audio, augmented_labels = self.batch_augment_data(
                audio_files, labels, augmentation_factor=2
            )
            
            # 2. ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ
            print("2ï¸âƒ£ ê³ ê¸‰ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            features_list = []
            for audio_data in augmented_audio:
                features = self.extract_advanced_features(audio_data, 16000)
                # ë”•ì…”ë„ˆë¦¬ë¥¼ í‰íƒ„í™”
                flat_features = []
                for key, value in features.items():
                    if isinstance(value, list):
                        flat_features.extend(value)
                    else:
                        flat_features.append(value)
                features_list.append(flat_features)
            
            X = np.array(features_list)
            y = np.array(augmented_labels)
            
            # 3. íŠ¹ì§• ì„ íƒ
            print("3ï¸âƒ£ íŠ¹ì§• ì„ íƒ ì¤‘...")
            X_selected = self.select_best_features(X, y, method='mutual_info', k=30)
            
            # 4. ì•¡í‹°ë¸Œ í•™ìŠµ
            print("4ï¸âƒ£ ì•¡í‹°ë¸Œ í•™ìŠµ ì¤‘...")
            active_learning_result = self.active_learning_pipeline(
                X_selected, y, initial_size=50, query_size=5, max_iterations=5
            )
            
            # 5. ì²˜ë¦¬ ì‹œê°„ ìµœì í™”
            print("5ï¸âƒ£ ì²˜ë¦¬ ì‹œê°„ ìµœì í™” ì¤‘...")
            optimization_result = self.optimize_processing_time(X_selected, y)
            
            # 6. GPU ì¤€ë¹„ ì½”ë“œ
            print("6ï¸âƒ£ GPU ì¤€ë¹„ ì½”ë“œ ìƒì„± ì¤‘...")
            gpu_ready_result = self.prepare_gpu_ready_code(X_selected, y)
            
            # 7. ì„±ëŠ¥ í‰ê°€
            print("7ï¸âƒ£ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
            X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)
            
            if active_learning_result['model'] is not None:
                final_model = active_learning_result['model']
            else:
                final_model = optimization_result['model']
            
            if final_model is not None:
                final_model.fit(X_train, y_train)
                y_pred = final_model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
            else:
                accuracy = 0.0
            
            results = {
                'accuracy': accuracy,
                'active_learning': active_learning_result,
                'optimization': optimization_result,
                'gpu_ready': gpu_ready_result,
                'feature_count': X_selected.shape[1],
                'total_samples': len(augmented_audio),
                'original_samples': len(audio_files),
                'improvement_methods': [
                    'data_augmentation',
                    'advanced_feature_extraction',
                    'feature_selection',
                    'active_learning',
                    'processing_time_optimization',
                    'gpu_ready_preparation'
                ]
            }
            
            print(f"âœ… ë…¸ë¦¬ìŠ¤í¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ì •í™•ë„: {accuracy:.3f}")
            return results
            
        except Exception as e:
            print(f"âŒ ë…¸ë¦¬ìŠ¤í¬ íŒŒì´í”„ë¼ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'accuracy': 0.0,
                'error': str(e),
                'improvement_methods': []
            }
    
    def batch_augment_data(self, audio_files: List[str], labels: List[int], 
                          augmentation_factor: int = 2) -> Tuple[List[np.ndarray], List[int]]:
        """ë°°ì¹˜ ë°ì´í„° ì¦ê°• (ì•ˆì „í•œ ë²„ì „)"""
        augmented_audio = []
        augmented_labels = []
        
        for audio_file, label in zip(audio_files, labels):
            try:
                audio_data, sr = librosa.load(audio_file, sr=16000)
                augmented_samples = self.augment_audio_data(audio_data, sr, augmentation_factor)
                
                augmented_audio.extend(augmented_samples)
                augmented_labels.extend([label] * len(augmented_samples))
                
            except Exception as e:
                print(f"âš ï¸ íŒŒì¼ ì¦ê°• ì˜¤ë¥˜ {audio_file} (ë¬´ì‹œí•˜ê³  ê³„ì†): {e}")
                continue
        
        return augmented_audio, augmented_labels

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ í…ŒìŠ¤íŠ¸
    improver = NoRiskAccuracyImprovements()
    
    print("ğŸ¯ ë…¸ë¦¬ìŠ¤í¬ ì •í™•ë„ í–¥ìƒ ë°©ë²•ë“¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ê°€ìƒì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_audio_files = ["test1.wav", "test2.wav", "test3.wav"]
    test_labels = [0, 1, 0]  # 0: ì •ìƒ, 1: ì´ìƒ
    
    # ë…¸ë¦¬ìŠ¤í¬ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = improver.no_risk_improvement_pipeline(test_audio_files, test_labels)
    
    print("ğŸ“Š ê²°ê³¼:")
    print(f"   ì •í™•ë„: {results['accuracy']:.3f}")
    print(f"   ì„ íƒëœ íŠ¹ì§• ìˆ˜: {results['feature_count']}")
    print(f"   ì´ ìƒ˜í”Œ ìˆ˜: {results['total_samples']}")
    print(f"   ì›ë³¸ ìƒ˜í”Œ ìˆ˜: {results['original_samples']}")
    print(f"   ê°œì„  ë°©ë²•ë“¤: {results['improvement_methods']}")
