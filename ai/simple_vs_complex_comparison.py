#!/usr/bin/env python3
"""
ê°„ë‹¨í•œ ê³µì‹ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ
ì‹¤ì œ ë°ì´í„°ë¡œ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë°©ë²•ì´ ë³µì¡í•œ AIë³´ë‹¤ ë‚˜ì€ì§€ ê²€ì¦
"""

import numpy as np
import librosa
import time
import warnings
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score, classification_report
from typing import Dict, List, Tuple
warnings.filterwarnings('ignore')

class SimpleVsComplexComparison:
    """ê°„ë‹¨í•œ ê³µì‹ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ"""
    
    def __init__(self):
        self.simple_rules = {}
        self.complex_models = {}
        self.performance_results = {}
        
        print("ğŸ” ê°„ë‹¨í•œ ê³µì‹ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
    
    # ===== 1. ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ë°©ë²• =====
    
    def create_simple_rules(self) -> Dict:
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì§„ë‹¨ ì‹œìŠ¤í…œ ìƒì„±"""
        rules = {
            'rms_threshold': 0.1,
            'zcr_threshold': 0.15,
            'spectral_centroid_threshold': 2000,
            'spectral_rolloff_threshold': 0.4,
            'spectral_bandwidth_threshold': 500
        }
        
        self.simple_rules = rules
        print("âœ… ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ ìƒì„± ì™„ë£Œ")
        return rules
    
    def simple_diagnosis(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì§„ë‹¨"""
        try:
            start_time = time.time()
            
            # ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ
            rms = np.sqrt(np.mean(audio_data ** 2))
            zcr = np.mean(librosa.feature.zero_crossing_rate(audio_data))
            spectral_centroid = np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr))
            spectral_rolloff = np.mean(librosa.feature.spectral_rolloff(y=audio_data, sr=sr))
            spectral_bandwidth = np.mean(librosa.feature.spectral_bandwidth(y=audio_data, sr=sr))
            
            # ê·œì¹™ ê¸°ë°˜ íŒë‹¨
            anomaly_score = 0
            reasons = []
            
            # RMS ê·œì¹™
            if rms > self.simple_rules['rms_threshold']:
                anomaly_score += 1
                reasons.append(f"RMS ë†’ìŒ: {rms:.3f} > {self.simple_rules['rms_threshold']}")
            
            # ZCR ê·œì¹™
            if zcr > self.simple_rules['zcr_threshold']:
                anomaly_score += 1
                reasons.append(f"ZCR ë†’ìŒ: {zcr:.3f} > {self.simple_rules['zcr_threshold']}")
            
            # Spectral Centroid ê·œì¹™
            if spectral_centroid > self.simple_rules['spectral_centroid_threshold']:
                anomaly_score += 1
                reasons.append(f"Spectral Centroid ë†’ìŒ: {spectral_centroid:.1f} > {self.simple_rules['spectral_centroid_threshold']}")
            
            # Spectral Rolloff ê·œì¹™
            if spectral_rolloff > self.simple_rules['spectral_rolloff_threshold']:
                anomaly_score += 1
                reasons.append(f"Spectral Rolloff ë†’ìŒ: {spectral_rolloff:.3f} > {self.simple_rules['spectral_rolloff_threshold']}")
            
            # Spectral Bandwidth ê·œì¹™
            if spectral_bandwidth > self.simple_rules['spectral_bandwidth_threshold']:
                anomaly_score += 1
                reasons.append(f"Spectral Bandwidth ë†’ìŒ: {spectral_bandwidth:.1f} > {self.simple_rules['spectral_bandwidth_threshold']}")
            
            # ìµœì¢… íŒë‹¨
            if anomaly_score >= 3:  # 3ê°œ ì´ìƒì˜ ê·œì¹™ì— í•´ë‹¹í•˜ë©´ ì´ìƒ
                prediction = 1  # ì´ìƒ
                confidence = min(0.9, 0.5 + (anomaly_score * 0.1))
            else:
                prediction = 0  # ì •ìƒ
                confidence = min(0.9, 0.5 + ((5 - anomaly_score) * 0.1))
            
            processing_time = time.time() - start_time
            
            return {
                'prediction': prediction,
                'confidence': confidence,
                'anomaly_score': anomaly_score,
                'reasons': reasons,
                'features': {
                    'rms': rms,
                    'zcr': zcr,
                    'spectral_centroid': spectral_centroid,
                    'spectral_rolloff': spectral_rolloff,
                    'spectral_bandwidth': spectral_bandwidth
                },
                'processing_time': processing_time,
                'method': 'simple_rules'
            }
            
        except Exception as e:
            print(f"âš ï¸ ê°„ë‹¨í•œ ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'prediction': 0,
                'confidence': 0.0,
                'anomaly_score': 0,
                'reasons': [],
                'features': {},
                'processing_time': 0.0,
                'method': 'simple_rules',
                'error': str(e)
            }
    
    # ===== 2. ë³µì¡í•œ AI ë°©ë²• =====
    
    def create_complex_models(self) -> Dict:
        """ë³µì¡í•œ AI ëª¨ë¸ë“¤ ìƒì„±"""
        models = {
            'random_forest': RandomForestClassifier(
                n_estimators=100,
                max_depth=20,
                min_samples_split=2,
                min_samples_leaf=1,
                random_state=42
            ),
            'neural_network': MLPClassifier(
                hidden_layer_sizes=(100, 50, 25),
                activation='relu',
                solver='adam',
                alpha=0.001,
                learning_rate='adaptive',
                max_iter=1000,
                random_state=42
            )
        }
        
        self.complex_models = models
        print("âœ… ë³µì¡í•œ AI ëª¨ë¸ë“¤ ìƒì„± ì™„ë£Œ")
        return models
    
    def extract_complex_features(self, audio_data: np.ndarray, sr: int) -> np.ndarray:
        """ë³µì¡í•œ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = []
            
            # ê¸°ë³¸ íŠ¹ì§•ë“¤
            features.append(np.sqrt(np.mean(audio_data ** 2)))  # RMS
            features.append(np.mean(librosa.feature.zero_crossing_rate(audio_data)))  # ZCR
            features.append(np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr)))  # Spectral Centroid
            features.append(np.mean(librosa.feature.spectral_rolloff(y=audio_data, sr=sr)))  # Spectral Rolloff
            features.append(np.mean(librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)))  # Spectral Bandwidth
            
            # MFCC (13ê°œ ê³„ìˆ˜)
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            features.extend(np.mean(mfccs, axis=1))
            features.extend(np.std(mfccs, axis=1))
            
            # Chroma (12ê°œ ê³„ìˆ˜)
            chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)
            features.extend(np.mean(chroma, axis=1))
            features.extend(np.std(chroma, axis=1))
            
            # Spectral Contrast (7ê°œ ê³„ìˆ˜)
            contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sr)
            features.extend(np.mean(contrast, axis=1))
            features.extend(np.std(contrast, axis=1))
            
            # Tonnetz (6ê°œ ê³„ìˆ˜)
            tonnetz = librosa.feature.tonnetz(y=audio_data, sr=sr)
            features.extend(np.mean(tonnetz, axis=1))
            
            # Poly Features (2ê°œ ê³„ìˆ˜)
            poly_features = librosa.feature.poly_features(y=audio_data, sr=sr)
            features.extend(np.mean(poly_features, axis=1))
            
            # Zero Crossing Rate (ê³ ê¸‰)
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features.append(np.mean(zcr))
            features.append(np.std(zcr))
            
            # Spectral Flatness
            flatness = librosa.feature.spectral_flatness(y=audio_data)
            features.append(np.mean(flatness))
            features.append(np.std(flatness))
            
            # Tempo
            try:
                tempo, _ = librosa.beat.beat_track(y=audio_data, sr=sr)
                features.append(tempo if tempo is not None else 0.0)
            except:
                features.append(0.0)
            
            return np.array(features)
            
        except Exception as e:
            print(f"âš ï¸ ë³µì¡í•œ íŠ¹ì§• ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
            return np.zeros(50)  # ê¸°ë³¸ê°’
    
    def complex_diagnosis(self, audio_data: np.ndarray, sr: int, model_name: str = 'random_forest') -> Dict:
        """ë³µì¡í•œ AI ì§„ë‹¨"""
        try:
            start_time = time.time()
            
            # ë³µì¡í•œ íŠ¹ì§• ì¶”ì¶œ
            features = self.extract_complex_features(audio_data, sr)
            
            # ëª¨ë¸ ì˜ˆì¸¡
            if model_name in self.complex_models:
                model = self.complex_models[model_name]
                
                # ì˜ˆì¸¡ ìˆ˜í–‰
                prediction = model.predict([features])[0]
                
                # ì‹ ë¢°ë„ ê³„ì‚° (í™•ë¥  ê¸°ë°˜)
                if hasattr(model, 'predict_proba'):
                    proba = model.predict_proba([features])[0]
                    confidence = np.max(proba)
                else:
                    confidence = 0.5  # ê¸°ë³¸ê°’
                
                processing_time = time.time() - start_time
                
                return {
                    'prediction': prediction,
                    'confidence': confidence,
                    'features': features,
                    'processing_time': processing_time,
                    'method': f'complex_{model_name}',
                    'feature_count': len(features)
                }
            else:
                raise ValueError(f"ëª¨ë¸ {model_name}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                
        except Exception as e:
            print(f"âš ï¸ ë³µì¡í•œ ì§„ë‹¨ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'prediction': 0,
                'confidence': 0.0,
                'features': np.zeros(50),
                'processing_time': 0.0,
                'method': f'complex_{model_name}',
                'error': str(e)
            }
    
    # ===== 3. ì„±ëŠ¥ ë¹„êµ =====
    
    def compare_performance(self, audio_files: List[str], labels: List[int]) -> Dict:
        """ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
        try:
            print("ğŸ” ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
            
            # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‹œìŠ¤í…œ ìƒì„±
            self.create_simple_rules()
            
            # ë³µì¡í•œ AI ëª¨ë¸ë“¤ ìƒì„±
            self.create_complex_models()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„
            X_simple = []
            X_complex = []
            y_true = []
            
            for audio_file, label in zip(audio_files, labels):
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    
                    # ê°„ë‹¨í•œ íŠ¹ì§• (ê·œì¹™ ê¸°ë°˜ì—ì„œ ì‚¬ìš©)
                    simple_features = self.simple_diagnosis(audio_data, sr)['features']
                    X_simple.append(simple_features)
                    
                    # ë³µì¡í•œ íŠ¹ì§• (AI ëª¨ë¸ì—ì„œ ì‚¬ìš©)
                    complex_features = self.extract_complex_features(audio_data, sr)
                    X_complex.append(complex_features)
                    
                    y_true.append(label)
                    
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜ {audio_file}: {e}")
                    continue
            
            X_simple = np.array(X_simple)
            X_complex = np.array(X_complex)
            y_true = np.array(y_true)
            
            # ë³µì¡í•œ ëª¨ë¸ë“¤ í›ˆë ¨
            for name, model in self.complex_models.items():
                try:
                    model.fit(X_complex, y_true)
                    print(f"âœ… {name} ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
                except Exception as e:
                    print(f"âŒ {name} ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
            
            # ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
            results = {}
            
            # 1. ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í…ŒìŠ¤íŠ¸
            print("1ï¸âƒ£ ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í…ŒìŠ¤íŠ¸")
            simple_results = self._test_simple_rules(audio_files, y_true)
            results['simple_rules'] = simple_results
            
            # 2. ë³µì¡í•œ AI ëª¨ë¸ë“¤ í…ŒìŠ¤íŠ¸
            for name, model in self.complex_models.items():
                print(f"2ï¸âƒ£ {name} ëª¨ë¸ í…ŒìŠ¤íŠ¸")
                complex_results = self._test_complex_model(audio_files, y_true, name)
                results[f'complex_{name}'] = complex_results
            
            # 3. ê²°ê³¼ ë¹„êµ
            comparison = self._compare_results(results)
            
            self.performance_results = {
                'individual_results': results,
                'comparison': comparison,
                'test_data_count': len(audio_files)
            }
            
            print("âœ… ì„±ëŠ¥ ë¹„êµ ì™„ë£Œ")
            return self.performance_results
            
        except Exception as e:
            print(f"âŒ ì„±ëŠ¥ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def _test_simple_rules(self, audio_files: List[str], y_true: List[int]) -> Dict:
        """ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ í…ŒìŠ¤íŠ¸"""
        try:
            predictions = []
            confidences = []
            processing_times = []
            
            for audio_file in audio_files:
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    result = self.simple_diagnosis(audio_data, sr)
                    
                    predictions.append(result['prediction'])
                    confidences.append(result['confidence'])
                    processing_times.append(result['processing_time'])
                    
                except Exception as e:
                    print(f"âš ï¸ ê°„ë‹¨í•œ ê·œì¹™ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ {audio_file}: {e}")
                    predictions.append(0)
                    confidences.append(0.0)
                    processing_times.append(0.0)
            
            accuracy = accuracy_score(y_true, predictions)
            avg_confidence = np.mean(confidences)
            avg_processing_time = np.mean(processing_times)
            
            return {
                'accuracy': accuracy,
                'avg_confidence': avg_confidence,
                'avg_processing_time': avg_processing_time,
                'predictions': predictions,
                'confidences': confidences,
                'processing_times': processing_times
            }
            
        except Exception as e:
            print(f"âš ï¸ ê°„ë‹¨í•œ ê·œì¹™ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'accuracy': 0.0,
                'avg_confidence': 0.0,
                'avg_processing_time': 0.0,
                'error': str(e)
            }
    
    def _test_complex_model(self, audio_files: List[str], y_true: List[int], model_name: str) -> Dict:
        """ë³µì¡í•œ AI ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
        try:
            predictions = []
            confidences = []
            processing_times = []
            
            for audio_file in audio_files:
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    result = self.complex_diagnosis(audio_data, sr, model_name)
                    
                    predictions.append(result['prediction'])
                    confidences.append(result['confidence'])
                    processing_times.append(result['processing_time'])
                    
                except Exception as e:
                    print(f"âš ï¸ ë³µì¡í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜ {audio_file}: {e}")
                    predictions.append(0)
                    confidences.append(0.0)
                    processing_times.append(0.0)
            
            accuracy = accuracy_score(y_true, predictions)
            avg_confidence = np.mean(confidences)
            avg_processing_time = np.mean(processing_times)
            
            return {
                'accuracy': accuracy,
                'avg_confidence': avg_confidence,
                'avg_processing_time': avg_processing_time,
                'predictions': predictions,
                'confidences': confidences,
                'processing_times': processing_times
            }
            
        except Exception as e:
            print(f"âš ï¸ ë³µì¡í•œ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'accuracy': 0.0,
                'avg_confidence': 0.0,
                'avg_processing_time': 0.0,
                'error': str(e)
            }
    
    def _compare_results(self, results: Dict) -> Dict:
        """ê²°ê³¼ ë¹„êµ"""
        try:
            comparison = {
                'accuracy_ranking': [],
                'speed_ranking': [],
                'confidence_ranking': [],
                'summary': {}
            }
            
            # ì •í™•ë„ ìˆœìœ„
            accuracy_scores = [(name, result['accuracy']) for name, result in results.items()]
            accuracy_scores.sort(key=lambda x: x[1], reverse=True)
            comparison['accuracy_ranking'] = accuracy_scores
            
            # ì†ë„ ìˆœìœ„ (ë¹ ë¥¸ ìˆœ)
            speed_scores = [(name, result['avg_processing_time']) for name, result in results.items()]
            speed_scores.sort(key=lambda x: x[1])
            comparison['speed_ranking'] = speed_scores
            
            # ì‹ ë¢°ë„ ìˆœìœ„
            confidence_scores = [(name, result['avg_confidence']) for name, result in results.items()]
            confidence_scores.sort(key=lambda x: x[1], reverse=True)
            comparison['confidence_ranking'] = confidence_scores
            
            # ìš”ì•½
            best_accuracy = accuracy_scores[0]
            fastest = speed_scores[0]
            most_confident = confidence_scores[0]
            
            comparison['summary'] = {
                'best_accuracy': best_accuracy,
                'fastest': fastest,
                'most_confident': most_confident,
                'simple_vs_complex': {
                    'simple_accuracy': results.get('simple_rules', {}).get('accuracy', 0),
                    'complex_accuracy': max([result.get('accuracy', 0) for name, result in results.items() if 'complex' in name]),
                    'simple_speed': results.get('simple_rules', {}).get('avg_processing_time', 0),
                    'complex_speed': min([result.get('avg_processing_time', float('inf')) for name, result in results.items() if 'complex' in name])
                }
            }
            
            return comparison
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ ë¹„êµ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}
    
    def print_comparison_results(self):
        """ë¹„êµ ê²°ê³¼ ì¶œë ¥"""
        if not self.performance_results:
            print("âŒ ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "=" * 60)
        print("ğŸ“Š ê°„ë‹¨í•œ ê³µì‹ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
        print("=" * 60)
        
        comparison = self.performance_results['comparison']
        
        # ì •í™•ë„ ìˆœìœ„
        print("\nğŸ† ì •í™•ë„ ìˆœìœ„:")
        for i, (name, accuracy) in enumerate(comparison['accuracy_ranking'], 1):
            print(f"   {i}. {name}: {accuracy:.3f}")
        
        # ì†ë„ ìˆœìœ„
        print("\nâš¡ ì†ë„ ìˆœìœ„ (ë¹ ë¥¸ ìˆœ):")
        for i, (name, speed) in enumerate(comparison['speed_ranking'], 1):
            print(f"   {i}. {name}: {speed*1000:.1f}ms")
        
        # ì‹ ë¢°ë„ ìˆœìœ„
        print("\nğŸ¯ ì‹ ë¢°ë„ ìˆœìœ„:")
        for i, (name, confidence) in enumerate(comparison['confidence_ranking'], 1):
            print(f"   {i}. {name}: {confidence:.3f}")
        
        # ìš”ì•½
        summary = comparison['summary']
        print("\nğŸ“‹ ìš”ì•½:")
        print(f"   ìµœê³  ì •í™•ë„: {summary['best_accuracy'][0]} ({summary['best_accuracy'][1]:.3f})")
        print(f"   ê°€ì¥ ë¹ ë¦„: {summary['fastest'][0]} ({summary['fastest'][1]*1000:.1f}ms)")
        print(f"   ê°€ì¥ ì‹ ë¢°ë„ ë†’ìŒ: {summary['most_confident'][0]} ({summary['most_confident'][1]:.3f})")
        
        # ê°„ë‹¨í•œ vs ë³µì¡í•œ ë¹„êµ
        simple_vs_complex = summary['simple_vs_complex']
        print("\nğŸ” ê°„ë‹¨í•œ vs ë³µì¡í•œ ë¹„êµ:")
        print(f"   ê°„ë‹¨í•œ ê³µì‹ ì •í™•ë„: {simple_vs_complex['simple_accuracy']:.3f}")
        print(f"   ë³µì¡í•œ AI ì •í™•ë„: {simple_vs_complex['complex_accuracy']:.3f}")
        print(f"   ê°„ë‹¨í•œ ê³µì‹ ì†ë„: {simple_vs_complex['simple_speed']*1000:.1f}ms")
        print(f"   ë³µì¡í•œ AI ì†ë„: {simple_vs_complex['complex_speed']*1000:.1f}ms")
        
        # ê²°ë¡ 
        if simple_vs_complex['simple_accuracy'] >= simple_vs_complex['complex_accuracy']:
            print("\nğŸ‰ ê²°ë¡ : ê°„ë‹¨í•œ ê³µì‹ì´ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤!")
        else:
            print("\nğŸ¤” ê²°ë¡ : ë³µì¡í•œ AIê°€ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤.")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ê°„ë‹¨í•œ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
    comparator = SimpleVsComplexComparison()
    
    print("ğŸ” ê°„ë‹¨í•œ ê³µì‹ vs ë³µì¡í•œ AI ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê°€ìƒì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_audio_files = ["test1.wav", "test2.wav", "test3.wav", "test4.wav", "test5.wav"]
    test_labels = [0, 1, 0, 1, 0]  # 0: ì •ìƒ, 1: ì´ìƒ
    
    # ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰
    results = comparator.compare_performance(test_audio_files, test_labels)
    
    if 'error' not in results:
        # ê²°ê³¼ ì¶œë ¥
        comparator.print_comparison_results()
    else:
        print(f"âŒ ì„±ëŠ¥ ë¹„êµ ì‹¤íŒ¨: {results['error']}")
