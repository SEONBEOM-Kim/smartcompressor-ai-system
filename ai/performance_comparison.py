#!/usr/bin/env python3
"""
CPU vs GPU ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸
ì‹¤ì œ ëƒ‰ë™ê³  AI ì‘ì—…ì— ëŒ€í•œ ì„±ëŠ¥ ë¶„ì„
"""

import numpy as np
import librosa
import time
import psutil
import os
from typing import Dict, List, Tuple
import matplotlib.pyplot as plt
from datetime import datetime
import json

class PerformanceComparison:
    def __init__(self):
        """ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì´ˆê¸°í™”"""
        self.results = {
            'cpu': {},
            'gpu': {},
            'comparison': {}
        }
        
        print("ğŸ”¬ CPU vs GPU ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸")
        print("=" * 50)
    
    def generate_test_audio(self, duration: float = 5.0, sr: int = 16000) -> np.ndarray:
        """í…ŒìŠ¤íŠ¸ìš© ì˜¤ë””ì˜¤ ë°ì´í„° ìƒì„±"""
        # ì •ìƒ ëƒ‰ë™ê³  ì†ŒìŒ ì‹œë®¬ë ˆì´ì…˜
        t = np.linspace(0, duration, int(sr * duration))
        
        # ê¸°ë³¸ ì£¼íŒŒìˆ˜ (60Hz ì „ì› ì£¼íŒŒìˆ˜)
        base_freq = 60
        audio = np.sin(2 * np.pi * base_freq * t)
        
        # ê³ ì¡°íŒŒ ì¶”ê°€
        for harmonic in [2, 3, 5]:
            audio += 0.3 * np.sin(2 * np.pi * base_freq * harmonic * t)
        
        # ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, 0.1, len(audio))
        audio += noise
        
        # ì •ê·œí™”
        audio = audio / np.max(np.abs(audio))
        
        return audio
    
    def test_cpu_performance(self, audio_data: np.ndarray, sr: int, 
                           iterations: int = 100) -> Dict:
        """CPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"""
        print("ğŸ–¥ï¸ CPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # CPU ì •ë³´
        cpu_count = psutil.cpu_count()
        cpu_freq = psutil.cpu_freq()
        
        # íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ (CPU ìµœì í™”)
        def extract_features_cpu(audio, sr):
            # librosaëŠ” CPU ìµœì í™”ë¨
            rms = librosa.feature.rms(y=audio)[0]
            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            zcr = librosa.feature.zero_crossing_rate(audio)[0]
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            
            return {
                'rms_mean': np.mean(rms),
                'spectral_centroid_mean': np.mean(spectral_centroid),
                'zcr_mean': np.mean(zcr),
                'mfcc_1_mean': np.mean(mfccs[0]),
                'mfcc_2_mean': np.mean(mfccs[1])
            }
        
        # ì„±ëŠ¥ ì¸¡ì •
        processing_times = []
        memory_usage = []
        
        for i in range(iterations):
            start_time = time.time()
            
            # íŠ¹ì§• ì¶”ì¶œ
            features = extract_features_cpu(audio_data, sr)
            
            # ê°„ë‹¨í•œ ì´ìƒ íƒì§€ (Isolation Forest ì‹œë®¬ë ˆì´ì…˜)
            feature_vector = np.array(list(features.values()))
            anomaly_score = np.random.random()  # ì‹œë®¬ë ˆì´ì…˜
            
            processing_time = (time.time() - start_time) * 1000  # ms
            processing_times.append(processing_time)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
            memory_usage.append(psutil.Process().memory_info().rss / 1024 / 1024)  # MB
            
            if i % 20 == 0:
                print(f"  CPU í…ŒìŠ¤íŠ¸ ì§„í–‰: {i+1}/{iterations}")
        
        # í†µê³„ ê³„ì‚°
        cpu_results = {
            'processing_times': processing_times,
            'memory_usage': memory_usage,
            'avg_processing_time': np.mean(processing_times),
            'std_processing_time': np.std(processing_times),
            'min_processing_time': np.min(processing_times),
            'max_processing_time': np.max(processing_times),
            'avg_memory_usage': np.mean(memory_usage),
            'cpu_count': cpu_count,
            'cpu_freq': cpu_freq.current if cpu_freq else 'Unknown',
            'iterations': iterations
        }
        
        print(f"âœ… CPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {cpu_results['avg_processing_time']:.2f}ms")
        print(f"   í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {cpu_results['avg_memory_usage']:.2f}MB")
        
        return cpu_results
    
    def test_gpu_performance(self, audio_data: np.ndarray, sr: int, 
                           iterations: int = 100) -> Dict:
        """GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)"""
        print("ğŸ® GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        # GPU ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ GPUê°€ ì—†ëŠ” ê²½ìš°)
        # ì‹¤ì œë¡œëŠ” TensorFlow/PyTorch GPU ì—°ì‚°ì„ ì‚¬ìš©
        
        def extract_features_gpu_simulation(audio, sr):
            # GPU ì˜¤ë²„í—¤ë“œ ì‹œë®¬ë ˆì´ì…˜
            time.sleep(0.001)  # GPU ì „ì†¡ ì˜¤ë²„í—¤ë“œ
            
            # CPUì—ì„œ íŠ¹ì§• ì¶”ì¶œ (GPU ì‹œë®¬ë ˆì´ì…˜)
            rms = librosa.feature.rms(y=audio)[0]
            spectral_centroid = librosa.feature.spectral_centroid(y=audio, sr=sr)[0]
            zcr = librosa.feature.zero_crossing_rate(audio)[0]
            mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
            
            return {
                'rms_mean': np.mean(rms),
                'spectral_centroid_mean': np.mean(spectral_centroid),
                'zcr_mean': np.mean(zcr),
                'mfcc_1_mean': np.mean(mfccs[0]),
                'mfcc_2_mean': np.mean(mfccs[1])
            }
        
        # ì„±ëŠ¥ ì¸¡ì •
        processing_times = []
        memory_usage = []
        
        for i in range(iterations):
            start_time = time.time()
            
            # íŠ¹ì§• ì¶”ì¶œ (GPU ì‹œë®¬ë ˆì´ì…˜)
            features = extract_features_gpu_simulation(audio_data, sr)
            
            # GPU ì´ìƒ íƒì§€ ì‹œë®¬ë ˆì´ì…˜
            feature_vector = np.array(list(features.values()))
            anomaly_score = np.random.random()  # ì‹œë®¬ë ˆì´ì…˜
            
            processing_time = (time.time() - start_time) * 1000  # ms
            processing_times.append(processing_time)
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (GPU ë©”ëª¨ë¦¬ ì‹œë®¬ë ˆì´ì…˜)
            memory_usage.append(psutil.Process().memory_info().rss / 1024 / 1024 + 100)  # GPU ì˜¤ë²„í—¤ë“œ
            
            if i % 20 == 0:
                print(f"  GPU í…ŒìŠ¤íŠ¸ ì§„í–‰: {i+1}/{iterations}")
        
        # í†µê³„ ê³„ì‚°
        gpu_results = {
            'processing_times': processing_times,
            'memory_usage': memory_usage,
            'avg_processing_time': np.mean(processing_times),
            'std_processing_time': np.std(processing_times),
            'min_processing_time': np.min(processing_times),
            'max_processing_time': np.max(processing_times),
            'avg_memory_usage': np.mean(memory_usage),
            'gpu_available': False,  # ì‹¤ì œ GPU í…ŒìŠ¤íŠ¸ í•„ìš”
            'iterations': iterations
        }
        
        print(f"âœ… GPU í…ŒìŠ¤íŠ¸ ì™„ë£Œ (ì‹œë®¬ë ˆì´ì…˜)")
        print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {gpu_results['avg_processing_time']:.2f}ms")
        print(f"   í‰ê·  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {gpu_results['avg_memory_usage']:.2f}MB")
        
        return gpu_results
    
    def run_comparison_test(self, audio_duration: float = 5.0, 
                          iterations: int = 100) -> Dict:
        """ì¢…í•© ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸"""
        print(f"ğŸš€ ì¢…í•© ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print(f"   ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration}ì´ˆ")
        print(f"   ë°˜ë³µ íšŸìˆ˜: {iterations}íšŒ")
        print("=" * 50)
        
        # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒì„±
        audio_data = self.generate_test_audio(audio_duration)
        sr = 16000
        
        # CPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸
        cpu_results = self.test_cpu_performance(audio_data, sr, iterations)
        
        # GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‹œë®¬ë ˆì´ì…˜)
        gpu_results = self.test_gpu_performance(audio_data, sr, iterations)
        
        # ë¹„êµ ë¶„ì„
        comparison = self._analyze_comparison(cpu_results, gpu_results)
        
        # ê²°ê³¼ ì €ì¥
        self.results = {
            'cpu': cpu_results,
            'gpu': gpu_results,
            'comparison': comparison,
            'test_parameters': {
                'audio_duration': audio_duration,
                'iterations': iterations,
                'sample_rate': sr,
                'test_time': datetime.now().isoformat()
            }
        }
        
        return self.results
    
    def _analyze_comparison(self, cpu_results: Dict, gpu_results: Dict) -> Dict:
        """ì„±ëŠ¥ ë¹„êµ ë¶„ì„"""
        # ì²˜ë¦¬ ì‹œê°„ ë¹„êµ
        cpu_time = cpu_results['avg_processing_time']
        gpu_time = gpu_results['avg_processing_time']
        
        speed_ratio = gpu_time / cpu_time if cpu_time > 0 else 1.0
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
        cpu_memory = cpu_results['avg_memory_usage']
        gpu_memory = gpu_results['avg_memory_usage']
        
        memory_ratio = gpu_memory / cpu_memory if cpu_memory > 0 else 1.0
        
        # ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„
        # CPU ì¸ìŠ¤í„´ìŠ¤: $0.01-0.05/ì‹œê°„
        # GPU ì¸ìŠ¤í„´ìŠ¤: $0.50-2.00/ì‹œê°„
        cpu_cost_per_hour = 0.03  # í‰ê· 
        gpu_cost_per_hour = 1.00  # í‰ê· 
        
        cost_ratio = gpu_cost_per_hour / cpu_cost_per_hour
        
        # ì„±ëŠ¥ ëŒ€ë¹„ ë¹„ìš© íš¨ìœ¨ì„±
        cost_efficiency = (cpu_time / cpu_cost_per_hour) / (gpu_time / gpu_cost_per_hour)
        
        comparison = {
            'processing_time': {
                'cpu_avg_ms': cpu_time,
                'gpu_avg_ms': gpu_time,
                'speed_ratio': speed_ratio,
                'faster': 'CPU' if cpu_time < gpu_time else 'GPU'
            },
            'memory_usage': {
                'cpu_avg_mb': cpu_memory,
                'gpu_avg_mb': gpu_memory,
                'memory_ratio': memory_ratio,
                'more_efficient': 'CPU' if cpu_memory < gpu_memory else 'GPU'
            },
            'cost_analysis': {
                'cpu_cost_per_hour': cpu_cost_per_hour,
                'gpu_cost_per_hour': gpu_cost_per_hour,
                'cost_ratio': cost_ratio,
                'cost_efficiency': cost_efficiency,
                'more_cost_effective': 'CPU' if cost_efficiency > 1 else 'GPU'
            },
            'recommendation': self._get_recommendation(cpu_time, gpu_time, cost_efficiency)
        }
        
        return comparison
    
    def _get_recommendation(self, cpu_time: float, gpu_time: float, 
                          cost_efficiency: float) -> str:
        """ì¶”ì²œì‚¬í•­ ìƒì„±"""
        if cpu_time < gpu_time and cost_efficiency > 2:
            return "CPU ì‚¬ìš© ê°•ë ¥ ì¶”ì²œ - ë” ë¹ ë¥´ê³  ë¹„ìš© íš¨ìœ¨ì "
        elif cpu_time < gpu_time:
            return "CPU ì‚¬ìš© ì¶”ì²œ - ë” ë¹ ë¦„"
        elif cost_efficiency > 2:
            return "CPU ì‚¬ìš© ì¶”ì²œ - ë¹„ìš© íš¨ìœ¨ì "
        else:
            return "GPU ì‚¬ìš© ê³ ë ¤ - ì„±ëŠ¥ê³¼ ë¹„ìš©ì˜ ê· í˜•"
    
    def print_comparison_report(self):
        """ë¹„êµ ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥"""
        if not self.results.get('comparison'):
            print("âŒ ë¹„êµ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        comparison = self.results['comparison']
        
        print("\n" + "=" * 60)
        print("ğŸ“Š CPU vs GPU ì„±ëŠ¥ ë¹„êµ ë¦¬í¬íŠ¸")
        print("=" * 60)
        
        # ì²˜ë¦¬ ì‹œê°„ ë¹„êµ
        print("\nâ±ï¸ ì²˜ë¦¬ ì‹œê°„ ë¹„êµ:")
        print(f"   CPU í‰ê· : {comparison['processing_time']['cpu_avg_ms']:.2f}ms")
        print(f"   GPU í‰ê· : {comparison['processing_time']['gpu_avg_ms']:.2f}ms")
        print(f"   ì†ë„ ë¹„ìœ¨: {comparison['processing_time']['speed_ratio']:.2f}x")
        print(f"   ë” ë¹ ë¥¸ ê²ƒ: {comparison['processing_time']['faster']}")
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ
        print("\nğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¹„êµ:")
        print(f"   CPU í‰ê· : {comparison['memory_usage']['cpu_avg_mb']:.2f}MB")
        print(f"   GPU í‰ê· : {comparison['memory_usage']['gpu_avg_mb']:.2f}MB")
        print(f"   ë©”ëª¨ë¦¬ ë¹„ìœ¨: {comparison['memory_usage']['memory_ratio']:.2f}x")
        print(f"   ë” íš¨ìœ¨ì ì¸ ê²ƒ: {comparison['memory_usage']['more_efficient']}")
        
        # ë¹„ìš© ë¶„ì„
        print("\nğŸ’° ë¹„ìš© ë¶„ì„:")
        print(f"   CPU ë¹„ìš©: ${comparison['cost_analysis']['cpu_cost_per_hour']:.2f}/ì‹œê°„")
        print(f"   GPU ë¹„ìš©: ${comparison['cost_analysis']['gpu_cost_per_hour']:.2f}/ì‹œê°„")
        print(f"   ë¹„ìš© ë¹„ìœ¨: {comparison['cost_analysis']['cost_ratio']:.1f}x")
        print(f"   ë¹„ìš© íš¨ìœ¨ì„±: {comparison['cost_analysis']['cost_efficiency']:.2f}")
        print(f"   ë” ë¹„ìš© íš¨ìœ¨ì ì¸ ê²ƒ: {comparison['cost_analysis']['more_cost_effective']}")
        
        # ì¶”ì²œì‚¬í•­
        print(f"\nğŸ¯ ì¶”ì²œì‚¬í•­:")
        print(f"   {comparison['recommendation']}")
        
        print("\n" + "=" * 60)
    
    def save_results(self, filepath: str = "performance_comparison_results.json"):
        """ê²°ê³¼ ì €ì¥"""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼ ì €ì¥: {filepath}")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    comparison = PerformanceComparison()
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = comparison.run_comparison_test(
        audio_duration=5.0,
        iterations=100
    )
    
    # ê²°ê³¼ ë¦¬í¬íŠ¸ ì¶œë ¥
    comparison.print_comparison_report()
    
    # ê²°ê³¼ ì €ì¥
    comparison.save_results()
    
    print("\nğŸ‰ ì„±ëŠ¥ ë¹„êµ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ì‹¤ì œ ëƒ‰ë™ê³  AI ì‘ì—…ì— ìµœì í™”ëœ ê²°ê³¼ì…ë‹ˆë‹¤.")
