#!/usr/bin/env python3
"""
ì²˜ë¦¬ ì‹œê°„ ìµœì í™” ë°©ë²•ë“¤
GPU ì—†ì´ë„ ë¹ ë¥¸ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‹¤ì–‘í•œ ìµœì í™” ê¸°ë²•ë“¤
"""

import numpy as np
import librosa
import time
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from functools import lru_cache
import joblib
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class ProcessingTimeOptimizer:
    """ì²˜ë¦¬ ì‹œê°„ ìµœì í™” í´ëž˜ìŠ¤"""
    
    def __init__(self):
        self.feature_cache = {}
        self.model_cache = {}
        self.performance_metrics = {}
        
        print("âš¡ ì²˜ë¦¬ ì‹œê°„ ìµœì í™” ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    # ===== 1. ìºì‹± ì‹œìŠ¤í…œ =====
    
    @lru_cache(maxsize=1000)
    def cached_feature_extraction(self, audio_hash: str, sr: int) -> Dict:
        """ìºì‹œëœ íŠ¹ì§• ì¶”ì¶œ"""
        # ì‹¤ì œë¡œëŠ” audio_hashë¥¼ ì‚¬ìš©í•˜ì—¬ ìºì‹œì—ì„œ ê°€ì ¸ì˜´
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ ì˜ˆì‹œ
        return {'feature_1': 0.5, 'feature_2': 0.3}
    
    def get_audio_hash(self, audio_data: np.ndarray) -> str:
        """ì˜¤ë””ì˜¤ ë°ì´í„°ì˜ í•´ì‹œ ìƒì„±"""
        return str(hash(audio_data.tobytes()))
    
    # ===== 2. ë³‘ë ¬ ì²˜ë¦¬ =====
    
    def parallel_feature_extraction(self, audio_data_list: List[np.ndarray], 
                                  sr: int, max_workers: int = 4) -> List[Dict]:
        """ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ"""
        def extract_features_single(audio_data):
            try:
                # ê°„ë‹¨í•œ íŠ¹ì§• ì¶”ì¶œ
                features = {
                    'rms': np.sqrt(np.mean(audio_data ** 2)),
                    'zcr': np.mean(librosa.feature.zero_crossing_rate(audio_data)),
                    'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr))
                }
                return features
            except:
                return {'rms': 0.0, 'zcr': 0.0, 'spectral_centroid': 0.0}
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            results = list(executor.map(extract_features_single, audio_data_list))
        
        return results
    
    def parallel_model_prediction(self, X: np.ndarray, models: List) -> List[np.ndarray]:
        """ë³‘ë ¬ ëª¨ë¸ ì˜ˆì¸¡"""
        def predict_single(model):
            try:
                return model.predict(X)
            except:
                return np.zeros(X.shape[0])
        
        with ThreadPoolExecutor(max_workers=len(models)) as executor:
            results = list(executor.map(predict_single, models))
        
        return results
    
    # ===== 3. ë°°ì¹˜ ì²˜ë¦¬ =====
    
    def batch_process_audio(self, audio_data_list: List[np.ndarray], 
                           batch_size: int = 32) -> List[Dict]:
        """ë°°ì¹˜ ì˜¤ë””ì˜¤ ì²˜ë¦¬"""
        results = []
        
        for i in range(0, len(audio_data_list), batch_size):
            batch = audio_data_list[i:i + batch_size]
            batch_results = self.parallel_feature_extraction(batch, 16000)
            results.extend(batch_results)
        
        return results
    
    # ===== 4. ë©”ëª¨ë¦¬ ìµœì í™” =====
    
    def memory_efficient_processing(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬"""
        try:
            # ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬
            chunk_size = int(5.0 * sr)  # 5ì´ˆ ì²­í¬
            features_list = []
            
            for i in range(0, len(audio_data), chunk_size):
                chunk = audio_data[i:i + chunk_size]
                if len(chunk) >= chunk_size:
                    # ê°„ë‹¨í•œ íŠ¹ì§•ë§Œ ì¶”ì¶œ
                    features = {
                        'rms': np.sqrt(np.mean(chunk ** 2)),
                        'zcr': np.mean(librosa.feature.zero_crossing_rate(chunk))
                    }
                    features_list.append(features)
            
            # ì²­í¬ë³„ íŠ¹ì§•ì„ í‰ê· 
            if features_list:
                final_features = {}
                for key in features_list[0].keys():
                    final_features[key] = np.mean([f[key] for f in features_list])
            else:
                final_features = {'rms': 0.0, 'zcr': 0.0}
            
            return final_features
            
        except Exception as e:
            print(f"âš ï¸ ë©”ëª¨ë¦¬ íš¨ìœ¨ì  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'rms': 0.0, 'zcr': 0.0}
    
    # ===== 5. ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© =====
    
    def create_fast_models(self) -> Dict:
        """ë¹ ë¥¸ ëª¨ë¸ë“¤ ìƒì„±"""
        from sklearn.ensemble import RandomForestClassifier
        from sklearn.linear_model import LogisticRegression
        from sklearn.naive_bayes import GaussianNB
        
        models = {
            'fast_rf': RandomForestClassifier(
                n_estimators=50,  # íŠ¸ë¦¬ ìˆ˜ ì¤„ì´ê¸°
                max_depth=10,     # ê¹Šì´ ì œí•œ
                random_state=42
            ),
            'logistic': LogisticRegression(
                max_iter=100,     # ë°˜ë³µ ìˆ˜ ì¤„ì´ê¸°
                random_state=42
            ),
            'naive_bayes': GaussianNB()
        }
        
        return models
    
    def fast_prediction(self, X: np.ndarray, model) -> np.ndarray:
        """ë¹ ë¥¸ ì˜ˆì¸¡"""
        try:
            # ì˜ˆì¸¡ ì‹œê°„ ì¸¡ì •
            start_time = time.time()
            y_pred = model.predict(X)
            prediction_time = time.time() - start_time
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì €ìž¥
            if 'prediction_times' not in self.performance_metrics:
                self.performance_metrics['prediction_times'] = []
            self.performance_metrics['prediction_times'].append(prediction_time)
            
            return y_pred
            
        except Exception as e:
            print(f"âš ï¸ ë¹ ë¥¸ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
            return np.zeros(X.shape[0])
    
    # ===== 6. íŠ¹ì§• ì••ì¶• =====
    
    def compress_features(self, X: np.ndarray, compression_ratio: float = 0.5) -> np.ndarray:
        """íŠ¹ì§• ì••ì¶•"""
        try:
            from sklearn.decomposition import PCA
            
            n_components = int(X.shape[1] * compression_ratio)
            n_components = max(1, min(n_components, X.shape[1]))
            
            pca = PCA(n_components=n_components)
            X_compressed = pca.fit_transform(X)
            
            return X_compressed
            
        except Exception as e:
            print(f"âš ï¸ íŠ¹ì§• ì••ì¶• ì¤‘ ì˜¤ë¥˜: {e}")
            return X
    
    # ===== 7. ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™” =====
    
    def real_time_optimization(self, audio_data: np.ndarray, sr: int) -> Dict:
        """ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”"""
        try:
            # 1. ë¹ ë¥¸ ì „ì²˜ë¦¬
            start_time = time.time()
            
            # ê°„ë‹¨í•œ í•„í„°ë§
            audio_filtered = audio_data
            
            # 2. ìµœì†Œí•œì˜ íŠ¹ì§•ë§Œ ì¶”ì¶œ
            features = {
                'rms': np.sqrt(np.mean(audio_filtered ** 2)),
                'zcr': np.mean(librosa.feature.zero_crossing_rate(audio_filtered)),
                'spectral_centroid': np.mean(librosa.feature.spectral_centroid(y=audio_filtered, sr=sr))
            }
            
            # 3. ë¹ ë¥¸ ì˜ˆì¸¡
            X = np.array([list(features.values())]).reshape(1, -1)
            
            # ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì˜ˆì¸¡ (ê°€ìž¥ ë¹ ë¦„)
            if features['rms'] > 0.1 and features['zcr'] > 0.1:
                prediction = 1  # ì´ìƒ
                confidence = 0.8
            else:
                prediction = 0  # ì •ìƒ
                confidence = 0.6
            
            processing_time = time.time() - start_time
            
            return {
                'prediction': prediction,
                'confidence': confidence,
                'processing_time': processing_time,
                'features': features
            }
            
        except Exception as e:
            print(f"âš ï¸ ì‹¤ì‹œê°„ ìµœì í™” ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'prediction': 0,
                'confidence': 0.0,
                'processing_time': 0.0,
                'features': {}
            }
    
    # ===== 8. GPU ì¤€ë¹„ ì½”ë“œ (GPU ì—†ì´ë„ ë™ìž‘) =====
    
    def gpu_ready_processing(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """GPU ì¤€ë¹„ ì½”ë“œ (GPU ì—†ì´ë„ ë™ìž‘)"""
        try:
            # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
            gpu_available = self._check_gpu_availability()
            
            if gpu_available:
                print("âœ… GPU ì‚¬ìš© ê°€ëŠ¥ - ë”¥ëŸ¬ë‹ ëª¨ë¸ ì‚¬ìš©")
                return self._gpu_processing(X, y)
            else:
                print("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€ - CPU ìµœì í™” ëª¨ë¸ ì‚¬ìš©")
                return self._cpu_optimized_processing(X, y)
                
        except Exception as e:
            print(f"âš ï¸ GPU ì¤€ë¹„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._cpu_optimized_processing(X, y)
    
    def _check_gpu_availability(self) -> bool:
        """GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸"""
        try:
            import torch
            return torch.cuda.is_available()
        except ImportError:
            return False
    
    def _gpu_processing(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """GPU ì²˜ë¦¬ (GPU ì‚¬ìš© ê°€ëŠ¥ ì‹œ)"""
        try:
            import torch
            import torch.nn as nn
            
            # ê°„ë‹¨í•œ ì‹ ê²½ë§
            class FastNN(nn.Module):
                def __init__(self, input_size, hidden_size=32, output_size=2):
                    super().__init__()
                    self.fc1 = nn.Linear(input_size, hidden_size)
                    self.fc2 = nn.Linear(hidden_size, output_size)
                    self.relu = nn.ReLU()
                
                def forward(self, x):
                    x = self.relu(self.fc1(x))
                    x = self.fc2(x)
                    return x
            
            model = FastNN(X.shape[1])
            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
            model = model.to(device)
            
            return {
                'model': model,
                'device': device,
                'processing_type': 'gpu',
                'gpu_available': True
            }
            
        except Exception as e:
            print(f"âš ï¸ GPU ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return self._cpu_optimized_processing(X, y)
    
    def _cpu_optimized_processing(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """CPU ìµœì í™” ì²˜ë¦¬"""
        try:
            from sklearn.ensemble import RandomForestClassifier
            from sklearn.linear_model import LogisticRegression
            
            # ë¹ ë¥¸ ëª¨ë¸ë“¤
            models = {
                'fast_rf': RandomForestClassifier(
                    n_estimators=50,
                    max_depth=10,
                    random_state=42
                ),
                'logistic': LogisticRegression(
                    max_iter=100,
                    random_state=42
                )
            }
            
            # ê°€ìž¥ ë¹ ë¥¸ ëª¨ë¸ ì„ íƒ
            fast_model = models['logistic']
            fast_model.fit(X, y)
            
            return {
                'model': fast_model,
                'device': 'cpu',
                'processing_type': 'cpu_optimized',
                'gpu_available': False
            }
            
        except Exception as e:
            print(f"âš ï¸ CPU ìµœì í™” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return {'model': None, 'device': 'cpu', 'processing_type': 'error', 'gpu_available': False}
    
    # ===== 9. í†µí•© ìµœì í™” íŒŒì´í”„ë¼ì¸ =====
    
    def comprehensive_optimization_pipeline(self, audio_files: List[str], 
                                          labels: List[int]) -> Dict:
        """ì¢…í•© ìµœì í™” íŒŒì´í”„ë¼ì¸"""
        
        print("âš¡ ì¢…í•© ì²˜ë¦¬ ì‹œê°„ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹œìž‘")
        
        try:
            # 1. ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ
            print("1ï¸âƒ£ ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ ì¤‘...")
            audio_data_list = []
            for audio_file in audio_files:
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    audio_data_list.append(audio_data)
                except:
                    continue
            
            # 2. ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ
            print("2ï¸âƒ£ ë³‘ë ¬ íŠ¹ì§• ì¶”ì¶œ ì¤‘...")
            start_time = time.time()
            features_list = self.parallel_feature_extraction(audio_data_list, 16000)
            feature_extraction_time = time.time() - start_time
            
            # 3. íŠ¹ì§• ì••ì¶•
            print("3ï¸âƒ£ íŠ¹ì§• ì••ì¶• ì¤‘...")
            X = np.array([list(f.values()) for f in features_list])
            X_compressed = self.compress_features(X, compression_ratio=0.5)
            
            # 4. ë¹ ë¥¸ ëª¨ë¸ í›ˆë ¨
            print("4ï¸âƒ£ ë¹ ë¥¸ ëª¨ë¸ í›ˆë ¨ ì¤‘...")
            start_time = time.time()
            fast_models = self.create_fast_models()
            training_times = {}
            
            for name, model in fast_models.items():
                model_start = time.time()
                model.fit(X_compressed, labels[:len(X_compressed)])
                training_times[name] = time.time() - model_start
            
            # 5. ë¹ ë¥¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
            print("5ï¸âƒ£ ë¹ ë¥¸ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸ ì¤‘...")
            prediction_times = {}
            for name, model in fast_models.items():
                start_time = time.time()
                y_pred = self.fast_prediction(X_compressed, model)
                prediction_times[name] = time.time() - start_time
            
            # 6. GPU ì¤€ë¹„ ì½”ë“œ
            print("6ï¸âƒ£ GPU ì¤€ë¹„ ì½”ë“œ ìƒì„± ì¤‘...")
            gpu_ready_result = self.gpu_ready_processing(X_compressed, labels[:len(X_compressed)])
            
            # 7. ì„±ëŠ¥ í‰ê°€
            print("7ï¸âƒ£ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
            from sklearn.model_selection import train_test_split
            from sklearn.metrics import accuracy_score
            
            X_train, X_test, y_train, y_test = train_test_split(
                X_compressed, labels[:len(X_compressed)], test_size=0.2, random_state=42
            )
            
            best_model = None
            best_accuracy = 0
            best_prediction_time = float('inf')
            
            for name, model in fast_models.items():
                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)
                accuracy = accuracy_score(y_test, y_pred)
                
                if accuracy > best_accuracy or (accuracy == best_accuracy and prediction_times[name] < best_prediction_time):
                    best_accuracy = accuracy
                    best_prediction_time = prediction_times[name]
                    best_model = model
            
            results = {
                'best_model': best_model,
                'best_accuracy': best_accuracy,
                'best_prediction_time': best_prediction_time,
                'feature_extraction_time': feature_extraction_time,
                'training_times': training_times,
                'prediction_times': prediction_times,
                'gpu_ready': gpu_ready_result,
                'compression_ratio': 0.5,
                'feature_count': X_compressed.shape[1],
                'total_samples': len(audio_data_list),
                'optimization_methods': [
                    'parallel_processing',
                    'feature_compression',
                    'fast_models',
                    'batch_processing',
                    'memory_optimization',
                    'gpu_ready_preparation'
                ]
            }
            
            print(f"âœ… ìµœì í™” íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
            print(f"   ìµœê³  ì •í™•ë„: {best_accuracy:.3f}")
            print(f"   ìµœê³  ì˜ˆì¸¡ ì‹œê°„: {best_prediction_time:.3f}ì´ˆ")
            print(f"   íŠ¹ì§• ì¶”ì¶œ ì‹œê°„: {feature_extraction_time:.3f}ì´ˆ")
            
            return results
            
        except Exception as e:
            print(f"âŒ ìµœì í™” íŒŒì´í”„ë¼ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            return {
                'best_accuracy': 0.0,
                'best_prediction_time': 0.0,
                'error': str(e),
                'optimization_methods': []
            }

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ì²˜ë¦¬ ì‹œê°„ ìµœì í™” í…ŒìŠ¤íŠ¸
    optimizer = ProcessingTimeOptimizer()
    
    print("âš¡ ì²˜ë¦¬ ì‹œê°„ ìµœì í™” ë°©ë²•ë“¤ í…ŒìŠ¤íŠ¸")
    print("=" * 50)
    
    # ê°€ìƒì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_audio_files = ["test1.wav", "test2.wav", "test3.wav"]
    test_labels = [0, 1, 0]  # 0: ì •ìƒ, 1: ì´ìƒ
    
    # ìµœì í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    results = optimizer.comprehensive_optimization_pipeline(test_audio_files, test_labels)
    
    print("ðŸ“Š ê²°ê³¼:")
    print(f"   ìµœê³  ì •í™•ë„: {results['best_accuracy']:.3f}")
    print(f"   ìµœê³  ì˜ˆì¸¡ ì‹œê°„: {results['best_prediction_time']:.3f}ì´ˆ")
    print(f"   íŠ¹ì§• ì¶”ì¶œ ì‹œê°„: {results['feature_extraction_time']:.3f}ì´ˆ")
    print(f"   íŠ¹ì§• ìˆ˜: {results['feature_count']}")
    print(f"   ìµœì í™” ë°©ë²•ë“¤: {results['optimization_methods']}")
