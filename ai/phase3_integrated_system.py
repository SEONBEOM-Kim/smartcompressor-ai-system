#!/usr/bin/env python3
"""
Phase 3: í†µí•© AI ì‹œìŠ¤í…œ ì™„ì„±
ëª¨ë“  AI ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ìµœì¢… ì‹œìŠ¤í…œ
"""

import numpy as np
import librosa
import time
import os
import json
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
from collections import deque
import threading
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.cluster import KMeans
import joblib
import statistics

class Phase3IntegratedSystem:
    def __init__(self, 
                 model_save_path: str = "data/models/phase3/",
                 window_size: float = 5.0,
                 sample_rate: int = 16000):
        """
        Phase 3 í†µí•© AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        
        Args:
            model_save_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
            window_size: ë¶„ì„ ìœˆë„ìš° í¬ê¸° (ì´ˆ)
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸
        """
        self.model_save_path = model_save_path
        os.makedirs(model_save_path, exist_ok=True)
        
        self.window_size = window_size
        self.sample_rate = sample_rate
        
        # í†µí•© ì‹œìŠ¤í…œ ì»´í¬ë„ŒíŠ¸ë“¤
        self.phase1_detector = None  # ê¸°ë³¸ ì´ìƒ íƒì§€
        self.phase2_adaptive = None  # ì ì‘í˜• ì‹œìŠ¤í…œ
        self.integrated_analyzer = None  # í†µí•© ë¶„ì„ê¸°
        
        # í†µí•© ì‹œìŠ¤í…œ íŒŒë¼ë¯¸í„°
        self.integration_params = {
            'phase1_weight': 0.3,  # Phase 1 ê°€ì¤‘ì¹˜
            'phase2_weight': 0.4,  # Phase 2 ê°€ì¤‘ì¹˜
            'integrated_weight': 0.3,  # í†µí•© ë¶„ì„ê¸° ê°€ì¤‘ì¹˜
            'consensus_threshold': 0.6,  # í•©ì˜ ì„ê³„ê°’
            'confidence_threshold': 0.7,  # ì‹ ë¢°ë„ ì„ê³„ê°’
            'reliability_threshold': 0.8  # ì‹ ë¢°ì„± ì„ê³„ê°’
        }
        
        # í†µí•© ì„±ëŠ¥ ì§€í‘œ
        self.integrated_metrics = {
            'total_detections': 0,
            'anomaly_count': 0,
            'false_positives': 0,
            'false_negatives': 0,
            'average_processing_time': 0.0,
            'accuracy': 0.0,
            'precision': 0.0,
            'recall': 0.0,
            'f1_score': 0.0,
            'system_reliability': 0.0,
            'consensus_rate': 0.0,
            'last_update': None
        }
        
        # ì‹œìŠ¤í…œ ìƒíƒœ
        self.system_status = {
            'phase1_ready': False,
            'phase2_ready': False,
            'integrated_ready': False,
            'overall_ready': False,
            'last_health_check': None
        }
        
        # í†µí•© ë¶„ì„ê¸° (ê³ ê¸‰ AI)
        self.integrated_analyzer = {
            'ensemble_model': None,
            'meta_classifier': None,
            'feature_selector': None,
            'anomaly_scorer': None,
            'reliability_estimator': None
        }
        
        # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
        self.monitoring_data = {
            'detection_history': deque(maxlen=1000),
            'performance_history': deque(maxlen=100),
            'system_health': deque(maxlen=50),
            'alert_history': deque(maxlen=100)
        }
        
        # ì•Œë¦¼ ì‹œìŠ¤í…œ
        self.alert_system = {
            'enabled': True,
            'thresholds': {
                'accuracy_drop': 0.1,  # ì •í™•ë„ 10% í•˜ë½
                'processing_time_increase': 2.0,  # ì²˜ë¦¬ ì‹œê°„ 2ë°° ì¦ê°€
                'anomaly_rate_spike': 0.3,  # ì´ìƒ íƒì§€ìœ¨ 30% ê¸‰ì¦
                'system_error_rate': 0.05  # ì‹œìŠ¤í…œ ì˜¤ë¥˜ìœ¨ 5%
            },
            'notification_channels': ['console', 'log', 'api']
        }
        
        print("ğŸ¯ Phase 3: í†µí•© AI ì‹œìŠ¤í…œ ì´ˆê¸°í™”")
        print(f"â±ï¸ ìœˆë„ìš° í¬ê¸°: {window_size}ì´ˆ")
        print(f"ğŸµ ìƒ˜í”Œë§ ë ˆì´íŠ¸: {sample_rate}Hz")
        print(f"ğŸ’¾ ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_save_path}")
        print(f"ğŸ”§ í†µí•© íŒŒë¼ë¯¸í„°: {self.integration_params}")
    
    def initialize_with_phases(self, phase1_detector, phase2_adaptive):
        """Phase 1, 2 ì‹œìŠ¤í…œìœ¼ë¡œ ì´ˆê¸°í™”"""
        self.phase1_detector = phase1_detector
        self.phase2_adaptive = phase2_adaptive
        
        # Phase 1 ìƒíƒœ í™•ì¸
        if phase1_detector and phase1_detector.is_trained:
            self.system_status['phase1_ready'] = True
            print("âœ… Phase 1 ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
        else:
            print("âŒ Phase 1 ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
        
        # Phase 2 ìƒíƒœ í™•ì¸
        if phase2_adaptive and phase2_adaptive.isInitialized:
            self.system_status['phase2_ready'] = True
            print("âœ… Phase 2 ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ")
        else:
            print("âŒ Phase 2 ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•ŠìŒ")
        
        # í†µí•© ë¶„ì„ê¸° ì´ˆê¸°í™”
        self._initialize_integrated_analyzer()
        
        # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸
        self._update_system_status()
        
        print("ğŸ¯ Phase 3 í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _initialize_integrated_analyzer(self):
        """í†µí•© ë¶„ì„ê¸° ì´ˆê¸°í™”"""
        # ì•™ìƒë¸” ëª¨ë¸ (ë‹¤ì¤‘ ì•Œê³ ë¦¬ì¦˜ í†µí•©)
        self.integrated_analyzer['ensemble_model'] = {
            'isolation_forest': IsolationForest(contamination=0.05, random_state=42),
            'one_class_svm': None,  # í–¥í›„ ì¶”ê°€
            'local_outlier_factor': None,  # í–¥í›„ ì¶”ê°€
            'autoencoder': None  # í–¥í›„ ì¶”ê°€
        }
        
        # ë©”íƒ€ ë¶„ë¥˜ê¸° (ì‹œìŠ¤í…œ ê°„ ì˜ˆì¸¡ í†µí•©)
        self.integrated_analyzer['meta_classifier'] = {
            'weights': {
                'phase1': self.integration_params['phase1_weight'],
                'phase2': self.integration_params['phase2_weight'],
                'integrated': self.integration_params['integrated_weight']
            },
            'bias': 0.0,
            'learning_rate': 0.01
        }
        
        # íŠ¹ì§• ì„ íƒê¸° (ì¤‘ìš” íŠ¹ì§• ì‹ë³„)
        self.integrated_analyzer['feature_selector'] = {
            'selected_features': [],
            'feature_importance': {},
            'selection_threshold': 0.1
        }
        
        # ì´ìƒ ì ìˆ˜ ê³„ì‚°ê¸°
        self.integrated_analyzer['anomaly_scorer'] = {
            'scoring_method': 'weighted_average',
            'normalization': 'min_max',
            'outlier_threshold': 0.8
        }
        
        # ì‹ ë¢°ì„± ì¶”ì •ê¸°
        self.integrated_analyzer['reliability_estimator'] = {
            'confidence_model': None,
            'uncertainty_threshold': 0.3,
            'reliability_threshold': 0.7
        }
        
        self.system_status['integrated_ready'] = True
        print("âœ… í†µí•© ë¶„ì„ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def detect_anomaly_integrated(self, audio_data: np.ndarray, sr: int, 
                                 ground_truth: Optional[bool] = None) -> Dict:
        """
        í†µí•© ì´ìƒ íƒì§€ ìˆ˜í–‰
        
        Args:
            audio_data: ì˜¤ë””ì˜¤ ë°ì´í„°
            sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸
            ground_truth: ì‹¤ì œ ì´ìƒ ì—¬ë¶€ (ì„±ëŠ¥ í‰ê°€ìš©)
            
        Returns:
            í†µí•© ì´ìƒ íƒì§€ ê²°ê³¼
        """
        if not self.system_status['overall_ready']:
            return {
                'is_anomaly': False,
                'confidence': 0.0,
                'message': 'í†µí•© ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.',
                'anomaly_type': 'system_not_ready',
                'processing_time_ms': 0,
                'phase': 'Phase 3'
            }
        
        start_time = time.time()
        
        try:
            # 1. Phase 1 ê¸°ë³¸ íƒì§€
            phase1_result = self._get_phase1_prediction(audio_data, sr, ground_truth)
            
            # 2. Phase 2 ì ì‘í˜• íƒì§€
            phase2_result = self._get_phase2_prediction(audio_data, sr, ground_truth)
            
            # 3. í†µí•© ë¶„ì„ê¸° íƒì§€
            integrated_result = self._get_integrated_prediction(audio_data, sr, ground_truth)
            
            # 4. ë©”íƒ€ ë¶„ë¥˜ê¸° í†µí•©
            final_result = self._integrate_meta_predictions(
                phase1_result, phase2_result, integrated_result
            )
            
            # 5. ì‹ ë¢°ì„± í‰ê°€
            reliability = self._assess_system_reliability(
                phase1_result, phase2_result, integrated_result
            )
            
            # 6. ìµœì¢… íŒì • ë° ì‹ ë¢°ë„ ì¡°ì •
            final_result = self._finalize_prediction(final_result, reliability)
            
            # 7. ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì—…ë°ì´íŠ¸
            processing_time = (time.time() - start_time) * 1000
            self._update_monitoring_data(final_result, ground_truth, processing_time)
            
            # 8. ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸
            self._update_integrated_metrics(final_result, ground_truth, processing_time)
            
            # 9. ì•Œë¦¼ ì‹œìŠ¤í…œ ì²´í¬
            self._check_alert_conditions()
            
            final_result['processing_time_ms'] = processing_time
            final_result['phase'] = 'Phase 3'
            final_result['system_reliability'] = reliability
            final_result['consensus_info'] = self._get_consensus_info(
                phase1_result, phase2_result, integrated_result
            )
            
            return final_result
            
        except Exception as e:
            print(f"âŒ í†µí•© ì´ìƒ íƒì§€ ì˜¤ë¥˜: {e}")
            return {
                'is_anomaly': False,
                'confidence': 0.0,
                'message': f'í†µí•© ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}',
                'anomaly_type': 'error',
                'processing_time_ms': (time.time() - start_time) * 1000,
                'phase': 'Phase 3'
            }
    
    def _get_phase1_prediction(self, audio_data: np.ndarray, sr: int, 
                              ground_truth: Optional[bool]) -> Dict:
        """Phase 1 ì˜ˆì¸¡ ê²°ê³¼"""
        if not self.system_status['phase1_ready']:
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'phase1_unavailable'}
        
        try:
            result = self.phase1_detector.detect_anomaly(audio_data, sr, ground_truth)
            return {
                'is_anomaly': result['is_anomaly'],
                'confidence': result['confidence'],
                'anomaly_type': result['anomaly_type'],
                'processing_time': result.get('processing_time_ms', 0),
                'system': 'Phase 1'
            }
        except Exception as e:
            print(f"âŒ Phase 1 ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'phase1_error'}
    
    def _get_phase2_prediction(self, audio_data: np.ndarray, sr: int, 
                              ground_truth: Optional[bool]) -> Dict:
        """Phase 2 ì˜ˆì¸¡ ê²°ê³¼"""
        if not self.system_status['phase2_ready']:
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'phase2_unavailable'}
        
        try:
            # Phase 2ëŠ” Node.js ì„œë¹„ìŠ¤ì´ë¯€ë¡œ ì‹œë®¬ë ˆì´ì…˜
            # ì‹¤ì œë¡œëŠ” HTTP API í˜¸ì¶œ
            result = self.phase2_adaptive.detectAnomalyAdaptive(audio_data, sr, ground_truth)
            return {
                'is_anomaly': result['is_anomaly'],
                'confidence': result['confidence'],
                'anomaly_type': result['anomaly_type'],
                'processing_time': result.get('processing_time_ms', 0),
                'system': 'Phase 2'
            }
        except Exception as e:
            print(f"âŒ Phase 2 ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'phase2_error'}
    
    def _get_integrated_prediction(self, audio_data: np.ndarray, sr: int, 
                                  ground_truth: Optional[bool]) -> Dict:
        """í†µí•© ë¶„ì„ê¸° ì˜ˆì¸¡ ê²°ê³¼"""
        if not self.system_status['integrated_ready']:
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'integrated_unavailable'}
        
        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = self.phase1_detector.extract_enhanced_features(audio_data, sr)
            feature_vector = np.array(list(features.values())).reshape(1, -1)
            
            # ì•™ìƒë¸” ëª¨ë¸ ì˜ˆì¸¡
            ensemble_scores = []
            for model_name, model in self.integrated_analyzer['ensemble_model'].items():
                if model is not None:
                    try:
                        score = model.score_samples(feature_vector)[0]
                        ensemble_scores.append(score)
                    except:
                        continue
            
            # ì•™ìƒë¸” ì ìˆ˜ í‰ê· 
            if ensemble_scores:
                avg_score = np.mean(ensemble_scores)
                is_anomaly = avg_score < 0
                confidence = min(1.0, abs(avg_score) / 2.0)
            else:
                is_anomaly = False
                confidence = 0.0
            
            # ì´ìƒ ìœ í˜• ë¶„ë¥˜
            anomaly_type = self._classify_integrated_anomaly_type(features, avg_score)
            
            return {
                'is_anomaly': is_anomaly,
                'confidence': confidence,
                'anomaly_type': anomaly_type,
                'processing_time': 0,  # í†µí•© ë¶„ì„ê¸°ëŠ” ë¹ ë¦„
                'system': 'Integrated',
                'ensemble_scores': ensemble_scores
            }
            
        except Exception as e:
            print(f"âŒ í†µí•© ë¶„ì„ê¸° ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return {'is_anomaly': False, 'confidence': 0.0, 'anomaly_type': 'integrated_error'}
    
    def _integrate_meta_predictions(self, phase1_result: Dict, 
                                   phase2_result: Dict, 
                                   integrated_result: Dict) -> Dict:
        """ë©”íƒ€ ë¶„ë¥˜ê¸°ë¥¼ í†µí•œ ì˜ˆì¸¡ í†µí•©"""
        
        # ê° ì‹œìŠ¤í…œì˜ ì˜ˆì¸¡ ìˆ˜ì§‘
        predictions = {
            'phase1': phase1_result,
            'phase2': phase2_result,
            'integrated': integrated_result
        }
        
        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        weights = self.integrated_analyzer['meta_classifier']['weights']
        bias = self.integrated_analyzer['meta_classifier']['bias']
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì¡°ì •
        adjusted_weights = {}
        total_weight = 0
        
        for system, result in predictions.items():
            if result['confidence'] > 0:  # ìœ íš¨í•œ ê²°ê³¼ë§Œ
                weight = weights[system] * result['confidence']
                adjusted_weights[system] = weight
                total_weight += weight
        
        # ì •ê·œí™”
        if total_weight > 0:
            for system in adjusted_weights:
                adjusted_weights[system] /= total_weight
        
        # ê°€ì¤‘ í‰ê·  ì‹ ë¢°ë„
        weighted_confidence = sum(
            result['confidence'] * adjusted_weights.get(system, 0)
            for system, result in predictions.items()
        )
        
        # ê°€ì¤‘ íˆ¬í‘œ
        votes = [result['is_anomaly'] for result in predictions.values() if result['confidence'] > 0]
        weighted_votes = sum(
            result['is_anomaly'] * adjusted_weights.get(system, 0)
            for system, result in predictions.items()
        )
        
        # ìµœì¢… íŒì •
        majority_vote = sum(votes) >= len(votes) / 2
        weighted_vote = weighted_votes >= 0.5
        
        # í•©ì˜ ê¸°ë°˜ ìµœì¢… íŒì •
        consensus = majority_vote and weighted_vote
        final_anomaly = consensus and weighted_confidence >= self.integration_params['confidence_threshold']
        
        # ì´ìƒ ìœ í˜• ê²°ì • (ê°€ì¥ ì‹ ë¢°ë„ê°€ ë†’ì€ ì‹œìŠ¤í…œì˜ ê²°ê³¼)
        best_system = max(predictions.keys(), 
                         key=lambda s: predictions[s]['confidence'])
        anomaly_type = predictions[best_system]['anomaly_type']
        
        return {
            'is_anomaly': final_anomaly,
            'confidence': weighted_confidence,
            'anomaly_type': anomaly_type,
            'meta_classification': {
                'predictions': predictions,
                'adjusted_weights': adjusted_weights,
                'majority_vote': majority_vote,
                'weighted_vote': weighted_vote,
                'consensus': consensus,
                'best_system': best_system
            }
        }
    
    def _assess_system_reliability(self, phase1_result: Dict, 
                                  phase2_result: Dict, 
                                  integrated_result: Dict) -> float:
        """ì‹œìŠ¤í…œ ì‹ ë¢°ì„± í‰ê°€"""
        
        # ê° ì‹œìŠ¤í…œì˜ ì‹ ë¢°ë„
        confidences = [
            phase1_result['confidence'],
            phase2_result['confidence'],
            integrated_result['confidence']
        ]
        
        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = np.mean([c for c in confidences if c > 0])
        
        # ì¼ê´€ì„± ì ìˆ˜ (ì‹œìŠ¤í…œ ê°„ ì˜ˆì¸¡ ì¼ì¹˜ë„)
        predictions = [
            phase1_result['is_anomaly'],
            phase2_result['is_anomaly'],
            integrated_result['is_anomaly']
        ]
        
        consistency = sum(predictions) / len(predictions) if predictions else 0.5
        consistency_score = 1.0 - abs(consistency - 0.5) * 2  # 0.5ì—ì„œ ë©€ìˆ˜ë¡ ë‚®ì€ ì ìˆ˜
        
        # ì‹ ë¢°ì„± ì ìˆ˜ (í‰ê·  ì‹ ë¢°ë„ + ì¼ê´€ì„±)
        reliability = 0.7 * avg_confidence + 0.3 * consistency_score
        
        return min(1.0, max(0.0, reliability))
    
    def _finalize_prediction(self, result: Dict, reliability: float) -> Dict:
        """ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ì™„ì„±"""
        
        # ì‹ ë¢°ì„± ê¸°ë°˜ ì‹ ë¢°ë„ ì¡°ì •
        adjusted_confidence = result['confidence'] * reliability
        
        # ì‹ ë¢°ì„± ì„ê³„ê°’ ì²´í¬
        if reliability < self.integration_params['reliability_threshold']:
            result['message'] = f"ì‹œìŠ¤í…œ ì‹ ë¢°ì„± ë‚®ìŒ ({reliability:.1%}). ê²°ê³¼ë¥¼ ì‹ ì¤‘íˆ ê²€í† í•˜ì„¸ìš”."
        else:
            result['message'] = f"ì‹œìŠ¤í…œ ì‹ ë¢°ì„± ì–‘í˜¸ ({reliability:.1%})"
        
        # ìµœì¢… ì‹ ë¢°ë„ ì ìš©
        result['confidence'] = adjusted_confidence
        result['reliability'] = reliability
        
        return result
    
    def _classify_integrated_anomaly_type(self, features: Dict[str, float], 
                                         ensemble_score: float) -> str:
        """í†µí•© ì´ìƒ ìœ í˜• ë¶„ë¥˜"""
        
        # íŠ¹ì§• ê¸°ë°˜ ë¶„ë¥˜
        if features.get('spectral_centroid', 0) > 2000 and features.get('zero_crossing_rate', 0) > 0.2:
            return 'bearing_wear'
        elif features.get('rms_energy', 0) > 1.0 or features.get('rms_energy', 0) < 0.01:
            return 'compressor_abnormal'
        elif features.get('low_freq_ratio', 0) > 0.8:
            return 'refrigerant_leak'
        elif features.get('high_freq_ratio', 0) > 0.6:
            return 'high_frequency_anomaly'
        elif ensemble_score < -1.0:
            return 'statistical_anomaly'
        else:
            return 'general_anomaly'
    
    def _get_consensus_info(self, phase1_result: Dict, 
                           phase2_result: Dict, 
                           integrated_result: Dict) -> Dict:
        """í•©ì˜ ì •ë³´ ìƒì„±"""
        
        predictions = [phase1_result['is_anomaly'], phase2_result['is_anomaly'], integrated_result['is_anomaly']]
        confidences = [phase1_result['confidence'], phase2_result['confidence'], integrated_result['confidence']]
        
        # í•©ì˜ìœ¨ ê³„ì‚°
        consensus_rate = sum(predictions) / len(predictions) if predictions else 0.5
        consensus_rate = 1.0 - abs(consensus_rate - 0.5) * 2
        
        # ì‹ ë¢°ë„ ë¶„ì‚°
        confidence_variance = np.var(confidences) if confidences else 0.0
        
        return {
            'consensus_rate': consensus_rate,
            'confidence_variance': confidence_variance,
            'system_agreement': consensus_rate > 0.7,
            'prediction_distribution': {
                'anomaly_count': sum(predictions),
                'total_systems': len(predictions),
                'confidence_range': [min(confidences), max(confidences)] if confidences else [0, 0]
            }
        }
    
    def _update_monitoring_data(self, result: Dict, ground_truth: Optional[bool], 
                               processing_time: float):
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ì—…ë°ì´íŠ¸"""
        
        # íƒì§€ íˆìŠ¤í† ë¦¬
        detection_record = {
            'timestamp': datetime.now(),
            'is_anomaly': result['is_anomaly'],
            'confidence': result['confidence'],
            'anomaly_type': result['anomaly_type'],
            'reliability': result.get('reliability', 0.0),
            'processing_time': processing_time,
            'ground_truth': ground_truth
        }
        self.monitoring_data['detection_history'].append(detection_record)
        
        # ì„±ëŠ¥ íˆìŠ¤í† ë¦¬
        performance_record = {
            'timestamp': datetime.now(),
            'accuracy': self.integrated_metrics['accuracy'],
            'processing_time': processing_time,
            'anomaly_rate': self.integrated_metrics['anomaly_count'] / max(1, self.integrated_metrics['total_detections'])
        }
        self.monitoring_data['performance_history'].append(performance_record)
        
        # ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ
        health_record = {
            'timestamp': datetime.now(),
            'phase1_ready': self.system_status['phase1_ready'],
            'phase2_ready': self.system_status['phase2_ready'],
            'integrated_ready': self.system_status['integrated_ready'],
            'overall_ready': self.system_status['overall_ready'],
            'reliability': result.get('reliability', 0.0)
        }
        self.monitoring_data['system_health'].append(health_record)
    
    def _update_integrated_metrics(self, result: Dict, ground_truth: Optional[bool], 
                                  processing_time: float):
        """í†µí•© ì„±ëŠ¥ ì§€í‘œ ì—…ë°ì´íŠ¸"""
        
        self.integrated_metrics['total_detections'] += 1
        
        if result['is_anomaly']:
            self.integrated_metrics['anomaly_count'] += 1
        
        # ì •í™•ë„ ê³„ì‚°
        if ground_truth is not None:
            predicted = result['is_anomaly']
            if predicted and not ground_truth:
                self.integrated_metrics['false_positives'] += 1
            elif not predicted and ground_truth:
                self.integrated_metrics['false_negatives'] += 1
            
            # ì •í™•ë„, ì •ë°€ë„, ì¬í˜„ìœ¨ ê³„ì‚°
            total = self.integrated_metrics['total_detections']
            correct = total - (self.integrated_metrics['false_positives'] + 
                             self.integrated_metrics['false_negatives'])
            
            self.integrated_metrics['accuracy'] = correct / total if total > 0 else 0.0
            
            # ì •ë°€ë„
            tp = self.integrated_metrics['anomaly_count'] - self.integrated_metrics['false_positives']
            self.integrated_metrics['precision'] = tp / self.integrated_metrics['anomaly_count'] if self.integrated_metrics['anomaly_count'] > 0 else 0.0
            
            # ì¬í˜„ìœ¨
            fn = self.integrated_metrics['false_negatives']
            self.integrated_metrics['recall'] = tp / (tp + fn) if (tp + fn) > 0 else 0.0
            
            # F1 ì ìˆ˜
            precision = self.integrated_metrics['precision']
            recall = self.integrated_metrics['recall']
            self.integrated_metrics['f1_score'] = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0
        
        # í‰ê·  ì²˜ë¦¬ ì‹œê°„ ì—…ë°ì´íŠ¸
        total = self.integrated_metrics['total_detections']
        current_avg = self.integrated_metrics['average_processing_time']
        self.integrated_metrics['average_processing_time'] = (
            (current_avg * (total - 1) + processing_time) / total
        )
        
        # ì‹œìŠ¤í…œ ì‹ ë¢°ì„± ì—…ë°ì´íŠ¸
        self.integrated_metrics['system_reliability'] = result.get('reliability', 0.0)
        
        # í•©ì˜ìœ¨ ì—…ë°ì´íŠ¸
        consensus_info = result.get('consensus_info', {})
        self.integrated_metrics['consensus_rate'] = consensus_info.get('consensus_rate', 0.0)
        
        self.integrated_metrics['last_update'] = datetime.now().isoformat()
    
    def _check_alert_conditions(self):
        """ì•Œë¦¼ ì¡°ê±´ ì²´í¬"""
        if not self.alert_system['enabled']:
            return
        
        alerts = []
        thresholds = self.alert_system['thresholds']
        
        # ì •í™•ë„ í•˜ë½ ì²´í¬
        if len(self.monitoring_data['performance_history']) >= 10:
            recent_accuracy = np.mean([p['accuracy'] for p in list(self.monitoring_data['performance_history'])[-10:]])
            if recent_accuracy < (self.integrated_metrics['accuracy'] - thresholds['accuracy_drop']):
                alerts.append({
                    'type': 'accuracy_drop',
                    'message': f'ì •í™•ë„ í•˜ë½ ê°ì§€: {recent_accuracy:.1%}',
                    'severity': 'warning'
                })
        
        # ì²˜ë¦¬ ì‹œê°„ ì¦ê°€ ì²´í¬
        if len(self.monitoring_data['performance_history']) >= 5:
            recent_processing_time = np.mean([p['processing_time'] for p in list(self.monitoring_data['performance_history'])[-5:]])
            if recent_processing_time > (self.integrated_metrics['average_processing_time'] * thresholds['processing_time_increase']):
                alerts.append({
                    'type': 'processing_time_increase',
                    'message': f'ì²˜ë¦¬ ì‹œê°„ ì¦ê°€ ê°ì§€: {recent_processing_time:.1f}ms',
                    'severity': 'warning'
                })
        
        # ì´ìƒ íƒì§€ìœ¨ ê¸‰ì¦ ì²´í¬
        if len(self.monitoring_data['detection_history']) >= 20:
            recent_anomaly_rate = sum(1 for d in list(self.monitoring_data['detection_history'])[-20:] if d['is_anomaly']) / 20
            if recent_anomaly_rate > thresholds['anomaly_rate_spike']:
                alerts.append({
                    'type': 'anomaly_rate_spike',
                    'message': f'ì´ìƒ íƒì§€ìœ¨ ê¸‰ì¦: {recent_anomaly_rate:.1%}',
                    'severity': 'critical'
                })
        
        # ì•Œë¦¼ ì²˜ë¦¬
        for alert in alerts:
            self._process_alert(alert)
    
    def _process_alert(self, alert: Dict):
        """ì•Œë¦¼ ì²˜ë¦¬"""
        alert['timestamp'] = datetime.now().isoformat()
        self.monitoring_data['alert_history'].append(alert)
        
        # ì½˜ì†” ì¶œë ¥
        if 'console' in self.alert_system['notification_channels']:
            print(f"ğŸš¨ ì•Œë¦¼: {alert['message']} (ì‹¬ê°ë„: {alert['severity']})")
        
        # ë¡œê·¸ íŒŒì¼ (í–¥í›„ êµ¬í˜„)
        if 'log' in self.alert_system['notification_channels']:
            # ë¡œê·¸ íŒŒì¼ì— ê¸°ë¡
            pass
        
        # API ì•Œë¦¼ (í–¥í›„ êµ¬í˜„)
        if 'api' in self.alert_system['notification_channels']:
            # ì™¸ë¶€ APIë¡œ ì•Œë¦¼ ì „ì†¡
            pass
    
    def _update_system_status(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ ì—…ë°ì´íŠ¸"""
        self.system_status['overall_ready'] = (
            self.system_status['phase1_ready'] and 
            self.system_status['phase2_ready'] and 
            self.system_status['integrated_ready']
        )
        self.system_status['last_health_check'] = datetime.now().isoformat()
    
    def get_integrated_stats(self) -> Dict:
        """í†µí•© ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        stats = self.integrated_metrics.copy()
        
        if stats['total_detections'] > 0:
            stats['anomaly_rate'] = stats['anomaly_count'] / stats['total_detections']
        else:
            stats['anomaly_rate'] = 0.0
        
        # ì¶”ê°€ í†µê³„
        stats.update({
            'phase': 'Phase 3',
            'system_status': self.system_status,
            'integration_params': self.integration_params,
            'monitoring_data_size': {
                'detection_history': len(self.monitoring_data['detection_history']),
                'performance_history': len(self.monitoring_data['performance_history']),
                'system_health': len(self.monitoring_data['system_health']),
                'alert_history': len(self.monitoring_data['alert_history'])
            },
            'last_update': datetime.now().isoformat()
        })
        
        return stats
    
    def get_monitoring_data(self, limit: int = 100) -> Dict:
        """ëª¨ë‹ˆí„°ë§ ë°ì´í„° ë°˜í™˜"""
        return {
            'detection_history': list(self.monitoring_data['detection_history'])[-limit:],
            'performance_history': list(self.monitoring_data['performance_history'])[-limit:],
            'system_health': list(self.monitoring_data['system_health'])[-limit:],
            'alert_history': list(self.monitoring_data['alert_history'])[-limit:]
        }
    
    def save_integrated_system(self, filepath: str = None):
        """í†µí•© ì‹œìŠ¤í…œ ì €ì¥"""
        if filepath is None:
            filepath = os.path.join(self.model_save_path, "phase3_integrated_system.pkl")
        
        # í†µí•© ì‹œìŠ¤í…œ ë°ì´í„° ì €ì¥
        integrated_data = {
            'integration_params': self.integration_params,
            'integrated_metrics': self.integrated_metrics,
            'system_status': self.system_status,
            'integrated_analyzer': self.integrated_analyzer,
            'alert_system': self.alert_system,
            'monitoring_data': dict(self.monitoring_data),  # dequeë¥¼ listë¡œ ë³€í™˜
            'window_size': self.window_size,
            'sample_rate': self.sample_rate,
            'phase': 'Phase 3'
        }
        
        joblib.dump(integrated_data, filepath)
        
        # ë©”íƒ€ë°ì´í„° ì €ì¥
        metadata = {
            'model_type': 'phase3_integrated_system',
            'phase': 'Phase 3',
            'created_at': datetime.now().isoformat(),
            'integration_params': self.integration_params,
            'integrated_metrics': self.integrated_metrics,
            'system_status': self.system_status,
            'window_size': self.window_size,
            'sample_rate': self.sample_rate
        }
        
        metadata_file = filepath.replace('.pkl', '_metadata.json')
        with open(metadata_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… Phase 3 í†µí•© ì‹œìŠ¤í…œ ì €ì¥ ì™„ë£Œ: {filepath}")
        print(f"ğŸ“Š ë©”íƒ€ë°ì´í„° ì €ì¥ ì™„ë£Œ: {metadata_file}")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # Phase 3 í†µí•© ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    integrated_system = Phase3IntegratedSystem()
    
    print("ğŸ¯ Phase 3: í†µí•© AI ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print("ëª¨ë“  AI ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•©í•œ ìµœì¢… ì‹œìŠ¤í…œ")
    print("ë©”íƒ€ ë¶„ë¥˜ê¸° ë° ì‹ ë¢°ì„± í‰ê°€")
    print("=" * 60)
    
    print("Phase 3 ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ!")
    print("Phase 1, 2 ì‹œìŠ¤í…œê³¼ ì—°ë™ í›„ í†µí•© ì´ìƒ íƒì§€ ê°€ëŠ¥")
    print("ì˜ˆìƒ ì •í™•ë„: 90-95%")
    print("ì˜ˆìƒ ì²˜ë¦¬ ì†ë„: 30-80ms")
    print("ì‹œìŠ¤í…œ ì‹ ë¢°ì„±: 95%+")
