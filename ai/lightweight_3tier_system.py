#!/usr/bin/env python3
"""
ê²½ëŸ‰í™”ëœ 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ
10-15ê°œ í•˜ë“œì›¨ì–´ë¡œ ë”¥ëŸ¬ë‹ + ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© + ì‹¤ì‹œê°„ ì ì‘í˜• í•™ìŠµ êµ¬í˜„
"""

import numpy as np
import librosa
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score, classification_report
import joblib
import psutil
import time
import threading
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

class Lightweight3TierSystem:
    """ê²½ëŸ‰í™”ëœ 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ"""
    
    def __init__(self, hardware_count: int = 10):
        self.hardware_count = hardware_count
        self.models = {}
        self.sensors = {}
        self.learning_systems = {}
        self.performance_metrics = {}
        
        # í•˜ë“œì›¨ì–´ ì‚¬ì–‘ í™•ì¸
        self.hardware_specs = self._check_hardware_specs()
        
        # ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self._initialize_system()
        
        print(f"ğŸš€ ê²½ëŸ‰í™”ëœ 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   í•˜ë“œì›¨ì–´ ìˆ˜: {hardware_count}")
        print(f"   CPU ì½”ì–´: {self.hardware_specs['cpu_cores']}")
        print(f"   RAM: {self.hardware_specs['ram_gb']}GB")
        print(f"   GPU ì‚¬ìš© ê°€ëŠ¥: {self.hardware_specs['gpu_available']}")
    
    def _check_hardware_specs(self) -> Dict:
        """í•˜ë“œì›¨ì–´ ì‚¬ì–‘ í™•ì¸"""
        try:
            specs = {
                'cpu_cores': psutil.cpu_count(logical=False),
                'ram_gb': round(psutil.virtual_memory().total / (1024**3), 1),
                'disk_gb': round(psutil.disk_usage('/').total / (1024**3), 1),
                'gpu_available': torch.cuda.is_available(),
                'network_mbps': 100  # ê¸°ë³¸ê°’
            }
            return specs
        except Exception as e:
            print(f"âš ï¸ í•˜ë“œì›¨ì–´ ì‚¬ì–‘ í™•ì¸ ì˜¤ë¥˜: {e}")
            return {
                'cpu_cores': 4,
                'ram_gb': 8,
                'disk_gb': 50,
                'gpu_available': False,
                'network_mbps': 100
            }
    
    def _initialize_system(self):
        """ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            # 1. ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™”
            self._initialize_lightweight_models()
            
            # 2. ê°€ìƒ ì„¼ì„œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_virtual_sensors()
            
            # 3. ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
            self._initialize_adaptive_learning()
            
            print("âœ… ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    def _initialize_lightweight_models(self):
        """ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™”"""
        try:
            # ê° í•˜ë“œì›¨ì–´ë³„ë¡œ ê²½ëŸ‰í™”ëœ ëª¨ë¸ ìƒì„±
            for i in range(self.hardware_count):
                model = LightweightCNN(
                    input_size=50,  # íŠ¹ì§• ìˆ˜
                    hidden_size=32,  # ì‘ì€ íˆë“  ë ˆì´ì–´
                    output_size=2   # ì´ì§„ ë¶„ë¥˜
                )
                
                # ëª¨ë¸ ì••ì¶• (CPU ìµœì í™”)
                if not self.hardware_specs['gpu_available']:
                    model = self._compress_model(model)
                
                self.models[i] = {
                    'model': model,
                    'optimizer': optim.Adam(model.parameters(), lr=0.001),
                    'criterion': nn.CrossEntropyLoss(),
                    'device': 'cuda' if self.hardware_specs['gpu_available'] else 'cpu'
                }
            
            print(f"âœ… ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ {self.hardware_count}ê°œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ë”¥ëŸ¬ë‹ ëª¨ë¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    def _compress_model(self, model):
        """ëª¨ë¸ ì••ì¶• (CPU ìµœì í™”)"""
        try:
            # ë™ì  ì–‘ìí™”
            model = torch.quantization.quantize_dynamic(
                model, {nn.Linear}, dtype=torch.qint8
            )
            return model
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì••ì¶• ì˜¤ë¥˜: {e}")
            return model
    
    def _initialize_virtual_sensors(self):
        """ê°€ìƒ ì„¼ì„œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            sensor_types = ['temperature', 'vibration', 'current', 'pressure', 'humidity']
            
            for i in range(self.hardware_count):
                sensor_type = sensor_types[i % len(sensor_types)]
                self.sensors[i] = VirtualSensor(
                    sensor_id=i,
                    sensor_type=sensor_type,
                    hardware_specs=self.hardware_specs
                )
            
            print(f"âœ… ê°€ìƒ ì„¼ì„œ {self.hardware_count}ê°œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ê°€ìƒ ì„¼ì„œ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    def _initialize_adaptive_learning(self):
        """ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        try:
            for i in range(self.hardware_count):
                self.learning_systems[i] = AdaptiveLearningSystem(
                    hardware_id=i,
                    model=self.models[i]['model'],
                    optimizer=self.models[i]['optimizer'],
                    criterion=self.models[i]['criterion']
                )
            
            print(f"âœ… ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ {self.hardware_count}ê°œ ì´ˆê¸°í™” ì™„ë£Œ")
            
        except Exception as e:
            print(f"âŒ ì ì‘í˜• í•™ìŠµ ì´ˆê¸°í™” ì˜¤ë¥˜: {e}")
    
    # ===== 1. ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ =====
    
    def train_lightweight_models(self, X: np.ndarray, y: np.ndarray) -> Dict:
        """ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨"""
        try:
            print("ğŸ§  ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì‹œì‘")
            
            # ë°ì´í„° ë¶„ì‚°
            chunk_size = len(X) // self.hardware_count
            training_results = {}
            
            for i in range(self.hardware_count):
                start = i * chunk_size
                end = start + chunk_size if i < self.hardware_count - 1 else len(X)
                
                X_chunk = X[start:end]
                y_chunk = y[start:end]
                
                # ê° í•˜ë“œì›¨ì–´ì—ì„œ ëª¨ë¸ í›ˆë ¨
                result = self._train_single_model(i, X_chunk, y_chunk)
                training_results[i] = result
            
            # ê²°ê³¼ í†µí•©
            overall_accuracy = np.mean([r['accuracy'] for r in training_results.values()])
            
            print(f"âœ… ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ! í‰ê·  ì •í™•ë„: {overall_accuracy:.3f}")
            
            return {
                'success': True,
                'overall_accuracy': overall_accuracy,
                'hardware_results': training_results
            }
            
        except Exception as e:
            print(f"âŒ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    def _train_single_model(self, hardware_id: int, X: np.ndarray, y: np.ndarray) -> Dict:
        """ë‹¨ì¼ í•˜ë“œì›¨ì–´ì—ì„œ ëª¨ë¸ í›ˆë ¨"""
        try:
            model_info = self.models[hardware_id]
            model = model_info['model']
            optimizer = model_info['optimizer']
            criterion = model_info['criterion']
            device = model_info['device']
            
            # ë°ì´í„°ë¥¼ í…ì„œë¡œ ë³€í™˜
            X_tensor = torch.FloatTensor(X)
            y_tensor = torch.LongTensor(y)
            
            if device == 'cuda':
                X_tensor = X_tensor.cuda()
                y_tensor = y_tensor.cuda()
                model = model.cuda()
            
            # í›ˆë ¨ ë£¨í”„
            model.train()
            for epoch in range(10):  # ì ì€ ì—í¬í¬
                optimizer.zero_grad()
                outputs = model(X_tensor)
                loss = criterion(outputs, y_tensor)
                loss.backward()
                optimizer.step()
            
            # ì •í™•ë„ ê³„ì‚°
            model.eval()
            with torch.no_grad():
                predictions = model(X_tensor)
                predicted_classes = torch.argmax(predictions, dim=1)
                accuracy = accuracy_score(y_tensor.cpu().numpy(), predicted_classes.cpu().numpy())
            
            return {
                'hardware_id': hardware_id,
                'accuracy': accuracy,
                'loss': loss.item(),
                'epochs': 10
            }
            
        except Exception as e:
            print(f"âŒ í•˜ë“œì›¨ì–´ {hardware_id} ëª¨ë¸ í›ˆë ¨ ì˜¤ë¥˜: {e}")
            return {
                'hardware_id': hardware_id,
                'accuracy': 0.0,
                'loss': float('inf'),
                'error': str(e)
            }
    
    # ===== 2. ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© =====
    
    def multi_sensor_fusion(self, audio_data: np.ndarray) -> Dict:
        """ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©"""
        try:
            print("ğŸ” ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© ì‹œì‘")
            
            # ê° ì„¼ì„œì—ì„œ ë°ì´í„° ìˆ˜ì§‘
            sensor_readings = {}
            for sensor_id, sensor in self.sensors.items():
                reading = sensor.simulate_reading(audio_data)
                sensor_readings[sensor_id] = reading
            
            # ì„¼ì„œ ë°ì´í„° ìœµí•©
            fused_result = self._fuse_sensor_data(sensor_readings)
            
            print(f"âœ… ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© ì™„ë£Œ! ìœµí•©ëœ íŠ¹ì§• ìˆ˜: {len(fused_result)}")
            
            return {
                'success': True,
                'sensor_readings': sensor_readings,
                'fused_features': fused_result,
                'fusion_method': 'weighted_average'
            }
            
        except Exception as e:
            print(f"âŒ ë‹¤ì¤‘ ì„¼ì„œ ìœµí•© ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    def _fuse_sensor_data(self, sensor_readings: Dict) -> np.ndarray:
        """ì„¼ì„œ ë°ì´í„° ìœµí•©"""
        try:
            # ê°€ì¤‘ í‰ê·  ìœµí•©
            weights = [1.0 / len(sensor_readings)] * len(sensor_readings)
            readings_array = np.array(list(sensor_readings.values()))
            
            # ê°€ì¤‘ í‰ê·  ê³„ì‚°
            fused_features = np.average(readings_array, axis=0, weights=weights)
            
            return fused_features
            
        except Exception as e:
            print(f"âš ï¸ ì„¼ì„œ ë°ì´í„° ìœµí•© ì˜¤ë¥˜: {e}")
            return np.zeros(50)  # ê¸°ë³¸ê°’
    
    # ===== 3. ì‹¤ì‹œê°„ ì ì‘í˜• í•™ìŠµ =====
    
    def adaptive_learning(self, audio_data: np.ndarray, ground_truth: int, hardware_id: int) -> Dict:
        """ì‹¤ì‹œê°„ ì ì‘í˜• í•™ìŠµ"""
        try:
            learning_system = self.learning_systems[hardware_id]
            
            # ì ì‘í˜• í•™ìŠµ ìˆ˜í–‰
            result = learning_system.learn(audio_data, ground_truth)
            
            return {
                'success': True,
                'hardware_id': hardware_id,
                'prediction': result['prediction'],
                'confidence': result['confidence'],
                'learning_rate': result['learning_rate'],
                'error': result['error']
            }
            
        except Exception as e:
            print(f"âŒ ì ì‘í˜• í•™ìŠµ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    # ===== 4. í†µí•© ì‹œìŠ¤í…œ =====
    
    def integrated_3tier_system(self, audio_files: List[str], labels: List[int]) -> Dict:
        """í†µí•© 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ"""
        try:
            print("ğŸš€ í†µí•© 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ ì‹œì‘")
            
            # 1. ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ ë° íŠ¹ì§• ì¶”ì¶œ
            print("1ï¸âƒ£ ì˜¤ë””ì˜¤ ë°ì´í„° ë¡œë“œ ë° íŠ¹ì§• ì¶”ì¶œ")
            features_list = []
            for audio_file in audio_files:
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    features = self._extract_lightweight_features(audio_data, sr)
                    features_list.append(features)
                except Exception as e:
                    print(f"âš ï¸ íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜ {audio_file}: {e}")
                    continue
            
            X = np.array(features_list)
            y = np.array(labels[:len(features_list)])
            
            # 2. ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨
            print("2ï¸âƒ£ ê²½ëŸ‰í™”ëœ ë”¥ëŸ¬ë‹ ëª¨ë¸ í›ˆë ¨")
            dl_result = self.train_lightweight_models(X, y)
            
            # 3. ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©
            print("3ï¸âƒ£ ë‹¤ì¤‘ ì„¼ì„œ ìœµí•©")
            sensor_result = self.multi_sensor_fusion(audio_data)
            
            # 4. ì ì‘í˜• í•™ìŠµ
            print("4ï¸âƒ£ ì ì‘í˜• í•™ìŠµ")
            adaptive_results = []
            for i, (audio_file, label) in enumerate(zip(audio_files, labels)):
                try:
                    audio_data, sr = librosa.load(audio_file, sr=16000)
                    hardware_id = i % self.hardware_count
                    adaptive_result = self.adaptive_learning(audio_data, label, hardware_id)
                    adaptive_results.append(adaptive_result)
                except Exception as e:
                    print(f"âš ï¸ ì ì‘í˜• í•™ìŠµ ì˜¤ë¥˜ {audio_file}: {e}")
                    continue
            
            # 5. ê²°ê³¼ í†µí•©
            print("5ï¸âƒ£ ê²°ê³¼ í†µí•©")
            final_result = self._integrate_results(dl_result, sensor_result, adaptive_results)
            
            print(f"âœ… í†µí•© 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ ì™„ë£Œ!")
            print(f"   ë”¥ëŸ¬ë‹ ì •í™•ë„: {dl_result.get('overall_accuracy', 0):.3f}")
            print(f"   ì„¼ì„œ ìœµí•© ì„±ê³µ: {sensor_result.get('success', False)}")
            print(f"   ì ì‘í˜• í•™ìŠµ ì„±ê³µ: {len([r for r in adaptive_results if r.get('success', False)])}")
            
            return final_result
            
        except Exception as e:
            print(f"âŒ í†µí•© ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    def _extract_lightweight_features(self, audio_data: np.ndarray, sr: int) -> np.ndarray:
        """ê²½ëŸ‰í™”ëœ íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = []
            
            # ê¸°ë³¸ íŠ¹ì§•ë“¤ë§Œ ì¶”ì¶œ (ì²˜ë¦¬ ì‹œê°„ ë‹¨ì¶•)
            features.append(np.sqrt(np.mean(audio_data ** 2)))  # RMS
            features.append(np.mean(librosa.feature.zero_crossing_rate(audio_data)))  # ZCR
            features.append(np.mean(librosa.feature.spectral_centroid(y=audio_data, sr=sr)))  # Spectral Centroid
            features.append(np.mean(librosa.feature.spectral_rolloff(y=audio_data, sr=sr)))  # Spectral Rolloff
            features.append(np.mean(librosa.feature.spectral_bandwidth(y=audio_data, sr=sr)))  # Spectral Bandwidth
            
            # MFCC (13ê°œ ê³„ìˆ˜)
            mfccs = librosa.feature.mfcc(y=audio_data, sr=sr, n_mfcc=13)
            features.extend(np.mean(mfccs, axis=1))
            
            # Chroma (12ê°œ ê³„ìˆ˜)
            chroma = librosa.feature.chroma_stft(y=audio_data, sr=sr)
            features.extend(np.mean(chroma, axis=1))
            
            # Spectral Contrast (7ê°œ ê³„ìˆ˜)
            contrast = librosa.feature.spectral_contrast(y=audio_data, sr=sr)
            features.extend(np.mean(contrast, axis=1))
            
            # Zero Crossing Rate (ê³ ê¸‰)
            zcr = librosa.feature.zero_crossing_rate(audio_data)
            features.append(np.mean(zcr))
            features.append(np.std(zcr))
            
            return np.array(features)
            
        except Exception as e:
            print(f"âš ï¸ íŠ¹ì§• ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            return np.zeros(50)  # ê¸°ë³¸ê°’
    
    def _integrate_results(self, dl_result: Dict, sensor_result: Dict, adaptive_results: List[Dict]) -> Dict:
        """ê²°ê³¼ í†µí•©"""
        try:
            # ë”¥ëŸ¬ë‹ ê²°ê³¼
            dl_accuracy = dl_result.get('overall_accuracy', 0.0)
            
            # ì„¼ì„œ ìœµí•© ê²°ê³¼
            sensor_success = sensor_result.get('success', False)
            sensor_features = sensor_result.get('fused_features', [])
            
            # ì ì‘í˜• í•™ìŠµ ê²°ê³¼
            adaptive_success_count = len([r for r in adaptive_results if r.get('success', False)])
            adaptive_total_count = len(adaptive_results)
            adaptive_success_rate = adaptive_success_count / adaptive_total_count if adaptive_total_count > 0 else 0
            
            # ìµœì¢… ì •í™•ë„ ê³„ì‚° (ê°€ì¤‘ í‰ê· )
            weights = [0.4, 0.3, 0.3]  # ë”¥ëŸ¬ë‹, ì„¼ì„œ, ì ì‘í˜• í•™ìŠµ
            final_accuracy = (
                weights[0] * dl_accuracy +
                weights[1] * (1.0 if sensor_success else 0.0) +
                weights[2] * adaptive_success_rate
            )
            
            return {
                'success': True,
                'final_accuracy': final_accuracy,
                'dl_accuracy': dl_accuracy,
                'sensor_success': sensor_success,
                'adaptive_success_rate': adaptive_success_rate,
                'hardware_count': self.hardware_count,
                'performance_metrics': {
                    'dl_accuracy': dl_accuracy,
                    'sensor_success': sensor_success,
                    'adaptive_success_rate': adaptive_success_rate,
                    'final_accuracy': final_accuracy
                }
            }
            
        except Exception as e:
            print(f"âš ï¸ ê²°ê³¼ í†µí•© ì˜¤ë¥˜: {e}")
            return {'success': False, 'error': str(e)}
    
    # ===== 5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ =====
    
    def get_performance_metrics(self) -> Dict:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        try:
            metrics = {
                'hardware_specs': self.hardware_specs,
                'model_count': len(self.models),
                'sensor_count': len(self.sensors),
                'learning_system_count': len(self.learning_systems),
                'timestamp': time.time()
            }
            
            return metrics
            
        except Exception as e:
            print(f"âš ï¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'error': str(e)}

# ===== ë³´ì¡° í´ë˜ìŠ¤ë“¤ =====

class LightweightCNN(nn.Module):
    """ê²½ëŸ‰í™”ëœ CNN ëª¨ë¸"""
    
    def __init__(self, input_size: int, hidden_size: int = 32, output_size: int = 2):
        super().__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.fc2 = nn.Linear(hidden_size, hidden_size)
        self.fc3 = nn.Linear(hidden_size, output_size)
        self.dropout = nn.Dropout(0.2)
    
    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout(x)
        x = self.fc3(x)
        return x

class VirtualSensor:
    """ê°€ìƒ ì„¼ì„œ í´ë˜ìŠ¤"""
    
    def __init__(self, sensor_id: int, sensor_type: str, hardware_specs: Dict):
        self.sensor_id = sensor_id
        self.sensor_type = sensor_type
        self.hardware_specs = hardware_specs
        self.calibration_data = self._load_calibration()
    
    def _load_calibration(self) -> Dict:
        """ì„¼ì„œ ë³´ì • ë°ì´í„° ë¡œë“œ"""
        return {
            'temp_coeff': 0.1,
            'vib_coeff': 0.05,
            'curr_coeff': 0.02,
            'press_coeff': 0.03,
            'hum_coeff': 0.08
        }
    
    def simulate_reading(self, audio_data: np.ndarray) -> np.ndarray:
        """ì„¼ì„œ ê°’ ì‹œë®¬ë ˆì´ì…˜"""
        try:
            if self.sensor_type == 'temperature':
                return self._extract_temperature(audio_data)
            elif self.sensor_type == 'vibration':
                return self._extract_vibration(audio_data)
            elif self.sensor_type == 'current':
                return self._extract_current(audio_data)
            elif self.sensor_type == 'pressure':
                return self._extract_pressure(audio_data)
            elif self.sensor_type == 'humidity':
                return self._extract_humidity(audio_data)
            else:
                return np.zeros(10)  # ê¸°ë³¸ê°’
                
        except Exception as e:
            print(f"âš ï¸ ì„¼ì„œ {self.sensor_id} ì‹œë®¬ë ˆì´ì…˜ ì˜¤ë¥˜: {e}")
            return np.zeros(10)
    
    def _extract_temperature(self, audio_data: np.ndarray) -> np.ndarray:
        """ì˜¨ë„ ì¶”ì¶œ"""
        spectral_centroid = librosa.feature.spectral_centroid(y=audio_data)
        temperature = self.calibration_data['temp_coeff'] * np.mean(spectral_centroid)
        return np.array([temperature] * 10)
    
    def _extract_vibration(self, audio_data: np.ndarray) -> np.ndarray:
        """ì§„ë™ ì¶”ì¶œ"""
        rms = np.sqrt(np.mean(audio_data ** 2))
        vibration = self.calibration_data['vib_coeff'] * rms
        return np.array([vibration] * 10)
    
    def _extract_current(self, audio_data: np.ndarray) -> np.ndarray:
        """ì „ë¥˜ ì¶”ì¶œ"""
        zcr = np.mean(librosa.feature.zero_crossing_rate(audio_data))
        current = self.calibration_data['curr_coeff'] * zcr
        return np.array([current] * 10)
    
    def _extract_pressure(self, audio_data: np.ndarray) -> np.ndarray:
        """ì••ë ¥ ì¶”ì¶œ"""
        spectral_rolloff = librosa.feature.spectral_rolloff(y=audio_data)
        pressure = self.calibration_data['press_coeff'] * np.mean(spectral_rolloff)
        return np.array([pressure] * 10)
    
    def _extract_humidity(self, audio_data: np.ndarray) -> np.ndarray:
        """ìŠµë„ ì¶”ì¶œ"""
        spectral_bandwidth = librosa.feature.spectral_bandwidth(y=audio_data)
        humidity = self.calibration_data['hum_coeff'] * np.mean(spectral_bandwidth)
        return np.array([humidity] * 10)

class AdaptiveLearningSystem:
    """ì ì‘í˜• í•™ìŠµ ì‹œìŠ¤í…œ"""
    
    def __init__(self, hardware_id: int, model, optimizer, criterion):
        self.hardware_id = hardware_id
        self.model = model
        self.optimizer = optimizer
        self.criterion = criterion
        self.learning_rate = 0.001
        self.error_history = []
        self.adaptation_count = 0
    
    def learn(self, audio_data: np.ndarray, ground_truth: int) -> Dict:
        """ì ì‘í˜• í•™ìŠµ ìˆ˜í–‰"""
        try:
            # íŠ¹ì§• ì¶”ì¶œ
            features = self._extract_features(audio_data)
            
            # ì˜ˆì¸¡ ìˆ˜í–‰
            prediction = self._predict(features)
            
            # ì˜¤ë¥˜ ê³„ì‚°
            error = abs(prediction - ground_truth)
            self.error_history.append(error)
            
            # ì ì‘í˜• í•™ìŠµë¥  ì¡°ì •
            self._adjust_learning_rate(error)
            
            # ëª¨ë¸ ì—…ë°ì´íŠ¸
            self._update_model(features, ground_truth)
            
            return {
                'prediction': prediction,
                'confidence': 1.0 - error,
                'learning_rate': self.learning_rate,
                'error': error,
                'adaptation_count': self.adaptation_count
            }
            
        except Exception as e:
            print(f"âš ï¸ ì ì‘í˜• í•™ìŠµ ì˜¤ë¥˜: {e}")
            return {
                'prediction': 0,
                'confidence': 0.0,
                'learning_rate': self.learning_rate,
                'error': 1.0,
                'adaptation_count': self.adaptation_count
            }
    
    def _extract_features(self, audio_data: np.ndarray) -> np.ndarray:
        """íŠ¹ì§• ì¶”ì¶œ"""
        try:
            features = [
                np.sqrt(np.mean(audio_data ** 2)),  # RMS
                np.mean(librosa.feature.zero_crossing_rate(audio_data)),  # ZCR
                np.mean(librosa.feature.spectral_centroid(y=audio_data))  # Spectral Centroid
            ]
            return np.array(features)
        except:
            return np.zeros(3)
    
    def _predict(self, features: np.ndarray) -> int:
        """ì˜ˆì¸¡ ìˆ˜í–‰"""
        try:
            with torch.no_grad():
                features_tensor = torch.FloatTensor(features).unsqueeze(0)
                output = self.model(features_tensor)
                prediction = torch.argmax(output, dim=1).item()
                return prediction
        except:
            return 0
    
    def _adjust_learning_rate(self, error: float):
        """í•™ìŠµë¥  ì¡°ì •"""
        if error > 0.1:  # ë†’ì€ ì˜¤ë¥˜
            self.learning_rate *= 1.1
        else:  # ë‚®ì€ ì˜¤ë¥˜
            self.learning_rate *= 0.9
        
        # í•™ìŠµë¥  ë²”ìœ„ ì œí•œ
        self.learning_rate = max(0.0001, min(0.01, self.learning_rate))
        
        # ì˜µí‹°ë§ˆì´ì € í•™ìŠµë¥  ì—…ë°ì´íŠ¸
        for param_group in self.optimizer.param_groups:
            param_group['lr'] = self.learning_rate
    
    def _update_model(self, features: np.ndarray, ground_truth: int):
        """ëª¨ë¸ ì—…ë°ì´íŠ¸"""
        try:
            self.model.train()
            self.optimizer.zero_grad()
            
            features_tensor = torch.FloatTensor(features).unsqueeze(0)
            target_tensor = torch.LongTensor([ground_truth])
            
            output = self.model(features_tensor)
            loss = self.criterion(output, target_tensor)
            
            loss.backward()
            self.optimizer.step()
            
            self.adaptation_count += 1
            
        except Exception as e:
            print(f"âš ï¸ ëª¨ë¸ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

# ì‚¬ìš© ì˜ˆì œ
if __name__ == "__main__":
    # ê²½ëŸ‰í™”ëœ 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
    system = Lightweight3TierSystem(hardware_count=10)
    
    print("ğŸš€ ê²½ëŸ‰í™”ëœ 3ìˆœìœ„ ì¡°í•© ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # ê°€ìƒì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_audio_files = ["test1.wav", "test2.wav", "test3.wav"]
    test_labels = [0, 1, 0]  # 0: ì •ìƒ, 1: ì´ìƒ
    
    # í†µí•© ì‹œìŠ¤í…œ ì‹¤í–‰
    results = system.integrated_3tier_system(test_audio_files, test_labels)
    
    if results['success']:
        print("ğŸ“Š ê²°ê³¼:")
        print(f"   ìµœì¢… ì •í™•ë„: {results['final_accuracy']:.3f}")
        print(f"   ë”¥ëŸ¬ë‹ ì •í™•ë„: {results['dl_accuracy']:.3f}")
        print(f"   ì„¼ì„œ ìœµí•© ì„±ê³µ: {results['sensor_success']}")
        print(f"   ì ì‘í˜• í•™ìŠµ ì„±ê³µë¥ : {results['adaptive_success_rate']:.3f}")
        print(f"   í•˜ë“œì›¨ì–´ ìˆ˜: {results['hardware_count']}")
    else:
        print(f"âŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì‹¤íŒ¨: {results['error']}")
