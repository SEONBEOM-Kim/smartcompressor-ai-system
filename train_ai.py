#!/usr/bin/env python3
"""
AI í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸ (train_ai.py)
ë¼ë²¨ë§ëœ ìŠ¤í™íŠ¸ë¡œê·¸ë¨ ë°ì´í„°ë¡œ CNN ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns
from datetime import datetime
import logging
import argparse

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AITrainer:
    """AI ëª¨ë¸ í›ˆë ¨ í´ë˜ìŠ¤"""
    
    def __init__(self, image_size=(256, 256), num_classes=3, batch_size=32, epochs=50):
        """
        Args:
            image_size (tuple): ì´ë¯¸ì§€ í¬ê¸° (width, height)
            num_classes (int): í´ë˜ìŠ¤ ìˆ˜ (ì •ìƒ, ëˆ„ì„¤, ê³¼ë¶€í•˜)
            batch_size (int): ë°°ì¹˜ í¬ê¸°
            epochs (int): í›ˆë ¨ ì—í¬í¬ ìˆ˜
        """
        self.image_size = image_size
        self.num_classes = num_classes
        self.batch_size = batch_size
        self.epochs = epochs
        self.model = None
        self.history = None
        self.label_encoder = LabelEncoder()
        
        # í´ë˜ìŠ¤ ë§¤í•‘
        self.class_names = ['ì •ìƒ ê°€ë™ìŒ', 'ëƒ‰ê¸° ëˆ„ì„¤ ì‹ í˜¸', 'ê³¼ë¶€í•˜ ì‹ í˜¸']
        self.class_mapping = {
            'normal': 0,
            'leak': 1, 
            'overload': 2
        }
    
    def load_labeled_data(self, labeled_data_dir="labeled_data"):
        """
        ë¼ë²¨ë§ëœ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            labeled_data_dir (str): ë¼ë²¨ë§ëœ ë°ì´í„° ë””ë ‰í† ë¦¬
            
        Returns:
            tuple: (images, labels) - ì´ë¯¸ì§€ ë°°ì—´ê³¼ ë¼ë²¨ ë°°ì—´
        """
        try:
            labeled_dir = Path(labeled_data_dir)
            
            if not labeled_dir.exists():
                raise FileNotFoundError(f"ë¼ë²¨ë§ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {labeled_data_dir}")
            
            images = []
            labels = []
            
            # ê° í´ë˜ìŠ¤ë³„ë¡œ ë°ì´í„° ë¡œë“œ
            for class_name, class_key in self.class_mapping.items():
                class_dir = labeled_dir / class_key
                
                if not class_dir.exists():
                    logger.warning(f"í´ë˜ìŠ¤ ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤: {class_dir}")
                    continue
                
                # ì´ë¯¸ì§€ íŒŒì¼ë“¤ ë¡œë“œ
                image_files = list(class_dir.glob("*.png")) + list(class_dir.glob("*.jpg")) + list(class_dir.glob("*.jpeg"))
                
                logger.info(f"í´ë˜ìŠ¤ '{class_name}': {len(image_files)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘...")
                
                for img_file in image_files:
                    try:
                        # ì´ë¯¸ì§€ ë¡œë“œ ë° ì „ì²˜ë¦¬
                        img = tf.keras.preprocessing.image.load_img(
                            img_file, 
                            target_size=self.image_size,
                            color_mode='rgb'
                        )
                        img_array = tf.keras.preprocessing.image.img_to_array(img)
                        img_array = img_array / 255.0  # ì •ê·œí™”
                        
                        images.append(img_array)
                        labels.append(class_key)
                        
                    except Exception as e:
                        logger.warning(f"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {img_file} - {e}")
                        continue
            
            if not images:
                raise ValueError("ë¡œë“œëœ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. ë¼ë²¨ë§ëœ ë°ì´í„°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # numpy ë°°ì—´ë¡œ ë³€í™˜
            images = np.array(images)
            labels = np.array(labels)
            
            logger.info(f"ì´ {len(images)}ê°œì˜ ì´ë¯¸ì§€ì™€ {len(labels)}ê°œì˜ ë¼ë²¨ì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
            logger.info(f"ì´ë¯¸ì§€ í˜•íƒœ: {images.shape}")
            logger.info(f"í´ë˜ìŠ¤ ë¶„í¬: {np.bincount(labels)}")
            
            return images, labels
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def create_cnn_model(self, input_shape):
        """
        CNN ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
        
        Args:
            input_shape (tuple): ì…ë ¥ ì´ë¯¸ì§€ í˜•íƒœ
            
        Returns:
            keras.Model: ìƒì„±ëœ CNN ëª¨ë¸
        """
        try:
            model = keras.Sequential([
                # ì…ë ¥ ë ˆì´ì–´
                layers.Input(shape=input_shape),
                
                # ì²« ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
                layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
                layers.BatchNormalization(),
                layers.Conv2D(32, (3, 3), activation='relu', padding='same'),
                layers.MaxPooling2D((2, 2)),
                layers.Dropout(0.25),
                
                # ë‘ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
                layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
                layers.BatchNormalization(),
                layers.Conv2D(64, (3, 3), activation='relu', padding='same'),
                layers.MaxPooling2D((2, 2)),
                layers.Dropout(0.25),
                
                # ì„¸ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
                layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
                layers.BatchNormalization(),
                layers.Conv2D(128, (3, 3), activation='relu', padding='same'),
                layers.MaxPooling2D((2, 2)),
                layers.Dropout(0.25),
                
                # ë„¤ ë²ˆì§¸ ì»¨ë³¼ë£¨ì…˜ ë¸”ë¡
                layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
                layers.BatchNormalization(),
                layers.Conv2D(256, (3, 3), activation='relu', padding='same'),
                layers.MaxPooling2D((2, 2)),
                layers.Dropout(0.25),
                
                # ì „ì—­ í‰ê·  í’€ë§
                layers.GlobalAveragePooling2D(),
                
                # ì™„ì „ ì—°ê²° ë ˆì´ì–´
                layers.Dense(512, activation='relu'),
                layers.BatchNormalization(),
                layers.Dropout(0.5),
                
                layers.Dense(256, activation='relu'),
                layers.BatchNormalization(),
                layers.Dropout(0.5),
                
                # ì¶œë ¥ ë ˆì´ì–´
                layers.Dense(self.num_classes, activation='softmax')
            ])
            
            # ëª¨ë¸ ì»´íŒŒì¼
            model.compile(
                optimizer=keras.optimizers.Adam(learning_rate=0.001),
                loss='sparse_categorical_crossentropy',
                metrics=['accuracy']
            )
            
            logger.info("CNN ëª¨ë¸ ìƒì„± ì™„ë£Œ")
            logger.info(f"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {model.count_params():,}")
            
            return model
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def train_model(self, images, labels, validation_split=0.2):
        """
        ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤.
        
        Args:
            images (np.array): í›ˆë ¨ ì´ë¯¸ì§€ ë°°ì—´
            labels (np.array): í›ˆë ¨ ë¼ë²¨ ë°°ì—´
            validation_split (float): ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
            
        Returns:
            keras.Model: í›ˆë ¨ëœ ëª¨ë¸
        """
        try:
            # ë°ì´í„° ë¶„í• 
            X_train, X_val, y_train, y_val = train_test_split(
                images, labels, 
                test_size=validation_split, 
                random_state=42, 
                stratify=labels
            )
            
            logger.info(f"í›ˆë ¨ ë°ì´í„°: {X_train.shape[0]}ê°œ")
            logger.info(f"ê²€ì¦ ë°ì´í„°: {X_val.shape[0]}ê°œ")
            
            # ëª¨ë¸ ìƒì„±
            self.model = self.create_cnn_model(X_train.shape[1:])
            
            # ì½œë°± ì„¤ì •
            callbacks = [
                keras.callbacks.EarlyStopping(
                    monitor='val_loss',
                    patience=10,
                    restore_best_weights=True
                ),
                keras.callbacks.ReduceLROnPlateau(
                    monitor='val_loss',
                    factor=0.5,
                    patience=5,
                    min_lr=1e-7
                ),
                keras.callbacks.ModelCheckpoint(
                    'best_model.h5',
                    monitor='val_accuracy',
                    save_best_only=True,
                    mode='max'
                )
            ]
            
            # ë°ì´í„° ì¦ê°•
            datagen = keras.preprocessing.image.ImageDataGenerator(
                rotation_range=20,
                width_shift_range=0.1,
                height_shift_range=0.1,
                horizontal_flip=True,
                zoom_range=0.1,
                fill_mode='nearest'
            )
            
            # ëª¨ë¸ í›ˆë ¨
            logger.info("ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
            self.history = self.model.fit(
                datagen.flow(X_train, y_train, batch_size=self.batch_size),
                steps_per_epoch=len(X_train) // self.batch_size,
                epochs=self.epochs,
                validation_data=(X_val, y_val),
                callbacks=callbacks,
                verbose=1
            )
            
            logger.info("ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
            if os.path.exists('best_model.h5'):
                self.model = keras.models.load_model('best_model.h5')
                logger.info("ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            
            return self.model
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            raise
    
    def plot_training_history(self, output_dir="results"):
        """
        í›ˆë ¨ ê³¼ì •ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.
        
        Args:
            output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        try:
            if self.history is None:
                logger.warning("í›ˆë ¨ íˆìŠ¤í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            os.makedirs(output_dir, exist_ok=True)
            
            # í›ˆë ¨ íˆìŠ¤í† ë¦¬ í”Œë¡¯
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
            
            # ì •í™•ë„
            ax1.plot(self.history.history['accuracy'], label='í›ˆë ¨ ì •í™•ë„')
            ax1.plot(self.history.history['val_accuracy'], label='ê²€ì¦ ì •í™•ë„')
            ax1.set_title('ëª¨ë¸ ì •í™•ë„')
            ax1.set_xlabel('ì—í¬í¬')
            ax1.set_ylabel('ì •í™•ë„')
            ax1.legend()
            ax1.grid(True)
            
            # ì†ì‹¤
            ax2.plot(self.history.history['loss'], label='í›ˆë ¨ ì†ì‹¤')
            ax2.plot(self.history.history['val_loss'], label='ê²€ì¦ ì†ì‹¤')
            ax2.set_title('ëª¨ë¸ ì†ì‹¤')
            ax2.set_xlabel('ì—í¬í¬')
            ax2.set_ylabel('ì†ì‹¤')
            ax2.legend()
            ax2.grid(True)
            
            plt.tight_layout()
            
            # ê²°ê³¼ ì €ì¥
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_path = os.path.join(output_dir, f"training_history_{timestamp}.png")
            plt.savefig(plot_path, dpi=300, bbox_inches='tight')
            plt.show()
            
            logger.info(f"í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì €ì¥: {plot_path}")
            
        except Exception as e:
            logger.error(f"í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def evaluate_model(self, X_test, y_test):
        """
        ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.
        
        Args:
            X_test (np.array): í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€
            y_test (np.array): í…ŒìŠ¤íŠ¸ ë¼ë²¨
        """
        try:
            if self.model is None:
                logger.error("í›ˆë ¨ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            # ì˜ˆì¸¡
            y_pred = self.model.predict(X_test)
            y_pred_classes = np.argmax(y_pred, axis=1)
            
            # ë¶„ë¥˜ ë³´ê³ ì„œ
            print("\n=== ë¶„ë¥˜ ë³´ê³ ì„œ ===")
            print(classification_report(
                y_test, y_pred_classes, 
                target_names=self.class_names
            ))
            
            # í˜¼ë™ í–‰ë ¬
            cm = confusion_matrix(y_test, y_pred_classes)
            
            plt.figure(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                       xticklabels=self.class_names,
                       yticklabels=self.class_names)
            plt.title('í˜¼ë™ í–‰ë ¬')
            plt.xlabel('ì˜ˆì¸¡ ë¼ë²¨')
            plt.ylabel('ì‹¤ì œ ë¼ë²¨')
            plt.tight_layout()
            plt.show()
            
            # ì •í™•ë„
            test_loss, test_accuracy = self.model.evaluate(X_test, y_test, verbose=0)
            print(f"\ní…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
            print(f"í…ŒìŠ¤íŠ¸ ì†ì‹¤: {test_loss:.4f}")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def save_model(self, model_path="model.h5", output_dir="models"):
        """
        í›ˆë ¨ëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            model_path (str): ëª¨ë¸ íŒŒì¼ëª…
            output_dir (str): ì €ì¥ ë””ë ‰í† ë¦¬
        """
        try:
            if self.model is None:
                logger.error("ì €ì¥í•  ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return
            
            os.makedirs(output_dir, exist_ok=True)
            
            # ëª¨ë¸ ì €ì¥
            full_path = os.path.join(output_dir, model_path)
            self.model.save(full_path)
            
            # í´ë˜ìŠ¤ ì •ë³´ ì €ì¥
            class_info_path = os.path.join(output_dir, "class_info.txt")
            with open(class_info_path, 'w', encoding='utf-8') as f:
                f.write("í´ë˜ìŠ¤ ë§¤í•‘:\n")
                for i, class_name in enumerate(self.class_names):
                    f.write(f"{i}: {class_name}\n")
            
            logger.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {full_path}")
            logger.info(f"í´ë˜ìŠ¤ ì •ë³´ ì €ì¥: {class_info_path}")
            
        except Exception as e:
            logger.error(f"ëª¨ë¸ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def main():
    """ë©”ì¸ í•¨ìˆ˜ - CLI ì¸í„°í˜ì´ìŠ¤"""
    parser = argparse.ArgumentParser(description='AI ëª¨ë¸ í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸')
    parser.add_argument('--data-dir', default='labeled_data', 
                       help='ë¼ë²¨ë§ëœ ë°ì´í„° ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: labeled_data)')
    parser.add_argument('--output-dir', default='models', 
                       help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: models)')
    parser.add_argument('--results-dir', default='results', 
                       help='ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: results)')
    parser.add_argument('--epochs', type=int, default=50, 
                       help='í›ˆë ¨ ì—í¬í¬ ìˆ˜ (ê¸°ë³¸ê°’: 50)')
    parser.add_argument('--batch-size', type=int, default=32, 
                       help='ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸ê°’: 32)')
    parser.add_argument('--image-size', nargs=2, type=int, default=[256, 256], 
                       help='ì´ë¯¸ì§€ í¬ê¸° (width height, ê¸°ë³¸ê°’: 256 256)')
    parser.add_argument('--validation-split', type=float, default=0.2, 
                       help='ê²€ì¦ ë°ì´í„° ë¹„ìœ¨ (ê¸°ë³¸ê°’: 0.2)')
    
    args = parser.parse_args()
    
    # í›ˆë ¨ê¸° ì´ˆê¸°í™”
    trainer = AITrainer(
        image_size=tuple(args.image_size),
        batch_size=args.batch_size,
        epochs=args.epochs
    )
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        logger.info("=== 1ë‹¨ê³„: ë¼ë²¨ë§ëœ ë°ì´í„° ë¡œë“œ ===")
        images, labels = trainer.load_labeled_data(args.data_dir)
        
        # 2. ëª¨ë¸ í›ˆë ¨
        logger.info("=== 2ë‹¨ê³„: ëª¨ë¸ í›ˆë ¨ ===")
        model = trainer.train_model(images, labels, args.validation_split)
        
        # 3. í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™”
        logger.info("=== 3ë‹¨ê³„: í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™” ===")
        trainer.plot_training_history(args.results_dir)
        
        # 4. ëª¨ë¸ ì €ì¥
        logger.info("=== 4ë‹¨ê³„: ëª¨ë¸ ì €ì¥ ===")
        trainer.save_model(output_dir=args.output_dir)
        
        print(f"\nâœ… AI ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
        print(f"ğŸ“ ëª¨ë¸ ì €ì¥ ìœ„ì¹˜: {args.output_dir}/model.h5")
        print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {args.results_dir}/")
        
    except Exception as e:
        logger.error(f"í›ˆë ¨ ì‹¤íŒ¨: {e}")
        return

if __name__ == "__main__":
    main()
